{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ofU59xluTupt"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your browser has been opened to visit:\n",
      "\n",
      "    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=764086051850-6qr4p6gpi6hn506pt8ejuq83di341hur.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8085%2F&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login&state=NAOWBMsPYVU6mgHqv3Z0QqQh4Kkxdx&access_type=offline&code_challenge=zJEbiB_zQ7thWGlT1q4WCGFUHmEIRvIhed00XQNksSA&code_challenge_method=S256\n",
      "\n",
      "\n",
      "Credentials saved to file: [/Users/zhuyu/.config/gcloud/application_default_credentials.json]\n",
      "\n",
      "These credentials will be used by any library that requests Application Default Credentials (ADC).\n",
      "\n",
      "Quota project \"carbon-virtue-378402\" was added to ADC which can be used by Google client libraries for billing and quota. Note that some services may still bill the project owning the resource.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['gcloud', 'auth', 'application-default', 'login'], returncode=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connect to the Google Account\n",
    "\n",
    "import subprocess\n",
    "# Install the Google Cloud SDK\n",
    "subprocess.run([\"gcloud\", \"auth\", \"application-default\", \"login\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "MQdMHMhVUV1G"
   },
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Initialize BigQuery client\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Function to run queries and return DataFrame\n",
    "def run_query(query):\n",
    "    return client.query(query).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QkUHA5NCF3Kv",
    "outputId": "7f602036-4763-4bec-acab-60b5ea6b3447"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhuyu/anaconda3/envs/COMP90089/lib/python3.12/site-packages/google/cloud/bigquery/table.py:1727: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   subject_id   hadm_id           admittime           dischtime gender  \\\n",
      "0    10000032  22841357 2180-06-26 18:27:00 2180-06-27 18:49:00      F   \n",
      "1    10000032  29079034 2180-07-23 12:35:00 2180-07-25 17:55:00      F   \n",
      "2    10000032  25742920 2180-08-05 23:44:00 2180-08-07 17:50:00      F   \n",
      "3    10000032  22595853 2180-05-06 22:23:00 2180-05-07 17:15:00      F   \n",
      "4    10000068  25022803 2160-03-03 23:16:00 2160-03-04 06:26:00      F   \n",
      "\n",
      "   approximate_age_at_admission   race  actual_age  in_hospital_death  \\\n",
      "0                            52  WHITE          52              False   \n",
      "1                            52  WHITE          52              False   \n",
      "2                            52  WHITE          52              False   \n",
      "3                            52  WHITE          52              False   \n",
      "4                            19  WHITE          19              False   \n",
      "\n",
      "   length_of_stay  \n",
      "0        1.015278  \n",
      "1        2.222222  \n",
      "2        1.754167  \n",
      "3        0.786111  \n",
      "4        0.298611  \n",
      "Number of rows in the dataset: 431089\n"
     ]
    }
   ],
   "source": [
    "# 1. Get basic patient info (admissions + demographics (excluding marital_status) + death status)\n",
    "patient_info_query = \"\"\"\n",
    "SELECT adm.subject_id, adm.hadm_id, adm.admittime, adm.dischtime, \n",
    "       pat.gender, pat.anchor_age AS approximate_age_at_admission, \n",
    "       adm.race, adm.hospital_expire_flag,\n",
    "       DATETIME_DIFF(adm.admittime, DATETIME(pat.anchor_year, 1, 1, 0, 0, 0), YEAR) + pat.anchor_age AS actual_age\n",
    "FROM `physionet-data.mimiciv_hosp.admissions` AS adm\n",
    "JOIN `physionet-data.mimiciv_hosp.patients` AS pat\n",
    "ON adm.subject_id = pat.subject_id\n",
    "WHERE adm.admittime IS NOT NULL\n",
    "ORDER BY subject_id\n",
    "\"\"\"\n",
    "patient_info_df = run_query(patient_info_query)\n",
    "\n",
    "# Set in-hospital death status\n",
    "patient_info_df['in_hospital_death'] = patient_info_df['hospital_expire_flag'] == 1\n",
    "patient_info_df = patient_info_df.drop(columns=['hospital_expire_flag'])\n",
    "\n",
    "# Calculate length of stay and keep data with positive L.O.S\n",
    "patient_info_df['admittime'] = pd.to_datetime(patient_info_df['admittime'])\n",
    "patient_info_df['dischtime'] = pd.to_datetime(patient_info_df['dischtime'])\n",
    "patient_info_df['length_of_stay'] = (patient_info_df['dischtime'] - patient_info_df['admittime']).dt.total_seconds() / (60 * 60 * 24)\n",
    "patient_info_df = patient_info_df[patient_info_df['length_of_stay'] > 0]\n",
    "\n",
    "# Display a sample of the resulting DataFrame\n",
    "print(patient_info_df.head())\n",
    "print(f\"Number of rows in the dataset: {patient_info_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "rKheWqKeGnMZ",
    "outputId": "14cd3905-30c4-439e-f2f8-d8bdecf85b9a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>admittime</th>\n",
       "      <th>dischtime</th>\n",
       "      <th>gender</th>\n",
       "      <th>approximate_age_at_admission</th>\n",
       "      <th>race</th>\n",
       "      <th>actual_age</th>\n",
       "      <th>in_hospital_death</th>\n",
       "      <th>length_of_stay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000032</td>\n",
       "      <td>22841357</td>\n",
       "      <td>2180-06-26 18:27:00</td>\n",
       "      <td>2180-06-27 18:49:00</td>\n",
       "      <td>F</td>\n",
       "      <td>52</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>52</td>\n",
       "      <td>False</td>\n",
       "      <td>1.015278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000032</td>\n",
       "      <td>29079034</td>\n",
       "      <td>2180-07-23 12:35:00</td>\n",
       "      <td>2180-07-25 17:55:00</td>\n",
       "      <td>F</td>\n",
       "      <td>52</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>52</td>\n",
       "      <td>False</td>\n",
       "      <td>2.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000032</td>\n",
       "      <td>25742920</td>\n",
       "      <td>2180-08-05 23:44:00</td>\n",
       "      <td>2180-08-07 17:50:00</td>\n",
       "      <td>F</td>\n",
       "      <td>52</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>52</td>\n",
       "      <td>False</td>\n",
       "      <td>1.754167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000032</td>\n",
       "      <td>22595853</td>\n",
       "      <td>2180-05-06 22:23:00</td>\n",
       "      <td>2180-05-07 17:15:00</td>\n",
       "      <td>F</td>\n",
       "      <td>52</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>52</td>\n",
       "      <td>False</td>\n",
       "      <td>0.786111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000068</td>\n",
       "      <td>25022803</td>\n",
       "      <td>2160-03-03 23:16:00</td>\n",
       "      <td>2160-03-04 06:26:00</td>\n",
       "      <td>F</td>\n",
       "      <td>19</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>19</td>\n",
       "      <td>False</td>\n",
       "      <td>0.298611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431226</th>\n",
       "      <td>19999828</td>\n",
       "      <td>29734428</td>\n",
       "      <td>2147-07-18 16:23:00</td>\n",
       "      <td>2147-08-04 18:10:00</td>\n",
       "      <td>F</td>\n",
       "      <td>46</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>46</td>\n",
       "      <td>False</td>\n",
       "      <td>17.074306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431227</th>\n",
       "      <td>19999828</td>\n",
       "      <td>25744818</td>\n",
       "      <td>2149-01-08 16:44:00</td>\n",
       "      <td>2149-01-18 17:00:00</td>\n",
       "      <td>F</td>\n",
       "      <td>46</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>48</td>\n",
       "      <td>False</td>\n",
       "      <td>10.011111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431228</th>\n",
       "      <td>19999840</td>\n",
       "      <td>26071774</td>\n",
       "      <td>2164-07-25 00:27:00</td>\n",
       "      <td>2164-07-28 12:15:00</td>\n",
       "      <td>M</td>\n",
       "      <td>58</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>58</td>\n",
       "      <td>False</td>\n",
       "      <td>3.491667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431229</th>\n",
       "      <td>19999840</td>\n",
       "      <td>21033226</td>\n",
       "      <td>2164-09-10 13:47:00</td>\n",
       "      <td>2164-09-17 13:42:00</td>\n",
       "      <td>M</td>\n",
       "      <td>58</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>58</td>\n",
       "      <td>True</td>\n",
       "      <td>6.996528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431230</th>\n",
       "      <td>19999987</td>\n",
       "      <td>23865745</td>\n",
       "      <td>2145-11-02 21:38:00</td>\n",
       "      <td>2145-11-11 12:57:00</td>\n",
       "      <td>F</td>\n",
       "      <td>57</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>57</td>\n",
       "      <td>False</td>\n",
       "      <td>8.638194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>431089 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        subject_id   hadm_id           admittime           dischtime gender  \\\n",
       "0         10000032  22841357 2180-06-26 18:27:00 2180-06-27 18:49:00      F   \n",
       "1         10000032  29079034 2180-07-23 12:35:00 2180-07-25 17:55:00      F   \n",
       "2         10000032  25742920 2180-08-05 23:44:00 2180-08-07 17:50:00      F   \n",
       "3         10000032  22595853 2180-05-06 22:23:00 2180-05-07 17:15:00      F   \n",
       "4         10000068  25022803 2160-03-03 23:16:00 2160-03-04 06:26:00      F   \n",
       "...            ...       ...                 ...                 ...    ...   \n",
       "431226    19999828  29734428 2147-07-18 16:23:00 2147-08-04 18:10:00      F   \n",
       "431227    19999828  25744818 2149-01-08 16:44:00 2149-01-18 17:00:00      F   \n",
       "431228    19999840  26071774 2164-07-25 00:27:00 2164-07-28 12:15:00      M   \n",
       "431229    19999840  21033226 2164-09-10 13:47:00 2164-09-17 13:42:00      M   \n",
       "431230    19999987  23865745 2145-11-02 21:38:00 2145-11-11 12:57:00      F   \n",
       "\n",
       "        approximate_age_at_admission     race  actual_age  in_hospital_death  \\\n",
       "0                                 52    WHITE          52              False   \n",
       "1                                 52    WHITE          52              False   \n",
       "2                                 52    WHITE          52              False   \n",
       "3                                 52    WHITE          52              False   \n",
       "4                                 19    WHITE          19              False   \n",
       "...                              ...      ...         ...                ...   \n",
       "431226                            46    WHITE          46              False   \n",
       "431227                            46    WHITE          48              False   \n",
       "431228                            58    WHITE          58              False   \n",
       "431229                            58    WHITE          58               True   \n",
       "431230                            57  UNKNOWN          57              False   \n",
       "\n",
       "        length_of_stay  \n",
       "0             1.015278  \n",
       "1             2.222222  \n",
       "2             1.754167  \n",
       "3             0.786111  \n",
       "4             0.298611  \n",
       "...                ...  \n",
       "431226       17.074306  \n",
       "431227       10.011111  \n",
       "431228        3.491667  \n",
       "431229        6.996528  \n",
       "431230        8.638194  \n",
       "\n",
       "[431089 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Adfsmdl1G3vL",
    "outputId": "2aae31e6-709b-4955-f16d-4f2932a10ef5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of patients: 180677\n"
     ]
    }
   ],
   "source": [
    "# Count number of patients\n",
    "num_patients = patient_info_df['subject_id'].nunique()\n",
    "print(f\"Number of patients: {num_patients}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NjSxcGc1xOX6",
    "outputId": "04dee535-373c-486d-c8af-a72572388a38"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhuyu/anaconda3/envs/COMP90089/lib/python3.12/site-packages/google/cloud/bigquery/table.py:1727: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   itemid   label category\n",
      "0  225672  Lipase     Labs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhuyu/anaconda3/envs/COMP90089/lib/python3.12/site-packages/google/cloud/bigquery/table.py:1727: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   itemid               label             fluid\n",
      "0   50956              Lipase             Blood\n",
      "1   50844     Lipase, Ascites           Ascites\n",
      "2   51055     Lipase, Pleural           Pleural\n",
      "3   51036  Lipase, Body Fluid  Other Body Fluid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhuyu/anaconda3/envs/COMP90089/lib/python3.12/site-packages/google/cloud/bigquery/table.py:1727: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       subject_id   hadm_id           charttime  lipase_level  \\\n",
      "1        10004606  29242151 2159-02-20 18:30:00        1222.0   \n",
      "17547    10006431  24638489 2129-01-23 23:36:00         508.0   \n",
      "15       10017531  22580355 2159-09-22 20:56:00        1164.0   \n",
      "17804    10021357  25937617 2144-12-30 06:55:00        1249.0   \n",
      "55       10036086  28728587 2196-05-26 09:25:00         677.0   \n",
      "\n",
      "                admittime           dischtime gender  \\\n",
      "1     2159-02-20 13:43:00 2159-03-06 16:51:00      F   \n",
      "17547 2129-01-24 01:08:00 2129-01-30 16:50:00      F   \n",
      "15    2159-09-22 19:30:00 2159-10-24 13:40:00      M   \n",
      "17804 2144-12-27 19:41:00 2145-01-04 19:54:00      F   \n",
      "55    2196-05-20 02:47:00 2196-06-12 11:42:00      M   \n",
      "\n",
      "       approximate_age_at_admission   race  actual_age  in_hospital_death  \\\n",
      "1                                64  WHITE          64              False   \n",
      "17547                            66  WHITE          67              False   \n",
      "15                               63  WHITE          64              False   \n",
      "17804                            91  WHITE          91              False   \n",
      "55                               57  WHITE          58              False   \n",
      "\n",
      "       length_of_stay  \n",
      "1           14.130556  \n",
      "17547        6.654167  \n",
      "15          31.756944  \n",
      "17804        8.009028  \n",
      "55          23.371528  \n",
      "Number of high lipase cases: 2299\n",
      "Number of unique patients with high lipase levels: 2104\n"
     ]
    }
   ],
   "source": [
    "# 2. Get high lipase level patients\n",
    "\n",
    "# Step 1: Retrieve item IDs for lipase tests in ICU\n",
    "lipase_item_query_icu = \"\"\"\n",
    "SELECT itemid, label, category\n",
    "FROM physionet-data.mimiciv_icu.d_items\n",
    "WHERE LOWER(label) LIKE '%lipase%'\n",
    "\"\"\"\n",
    "lipase_items_df_icu = run_query(lipase_item_query_icu)\n",
    "print(lipase_items_df_icu)\n",
    "lipase_itemids_icu = \"225672\"  # Lipase item ID for ICU\n",
    "\n",
    "# Step 2: Retrieve item IDs for lipase tests in hosp\n",
    "lipase_item_query_hosp = \"\"\"\n",
    "SELECT itemid, label, fluid\n",
    "FROM physionet-data.mimiciv_hosp.d_labitems\n",
    "WHERE LOWER(label) LIKE '%lipase%'\n",
    "\"\"\"\n",
    "lipase_items_df_hosp = run_query(lipase_item_query_hosp)\n",
    "print(lipase_items_df_hosp)\n",
    "lipase_items_hosp = [50956, 50844, 51055, 51036]  # Lipase item IDs for hosp\n",
    "\n",
    "# Step 3: Retrieve lipase values from ICU\n",
    "lipase_values_query_icu = f\"\"\"\n",
    "SELECT subject_id, hadm_id, charttime, valuenum AS lipase_level\n",
    "FROM `physionet-data.mimiciv_icu.chartevents`\n",
    "WHERE itemid IN ({lipase_itemids_icu})\n",
    "ORDER BY subject_id, charttime\n",
    "\"\"\"\n",
    "lipase_values_df_icu = run_query(lipase_values_query_icu)\n",
    "\n",
    "# Step 4: Retrieve lipase values from hosp\n",
    "lipase_values_query_hosp = f\"\"\"\n",
    "SELECT subject_id, hadm_id, charttime, valuenum AS lipase_level\n",
    "FROM `physionet-data.mimiciv_hosp.labevents`\n",
    "WHERE itemid IN ({', '.join(map(str, lipase_items_hosp))})\n",
    "ORDER BY subject_id, charttime\n",
    "\"\"\"\n",
    "lipase_values_df_hosp = run_query(lipase_values_query_hosp)\n",
    "\n",
    "# Step 5: Combine ICU and hosp lipase records\n",
    "lipase_values_df = pd.concat([lipase_values_df_icu, lipase_values_df_hosp], ignore_index=True)\n",
    "\n",
    "# Step 6: Merge with patient info to add age and other basic details (only one merge needed)\n",
    "lipase_values_df = pd.merge(\n",
    "    lipase_values_df,\n",
    "    patient_info_df.copy(),\n",
    "    on=['subject_id', 'hadm_id'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Step 7: Define a function to check high lipase levels based on age threshold\n",
    "def check_high_lipase(row, age_cutoff=60):\n",
    "    # Check if 'actual_age' is NaN and skip if so\n",
    "    if pd.isna(row['actual_age']):\n",
    "        return False  # or set a default value, depending on the requirement\n",
    "    \n",
    "    upper_limit = 140 if row['actual_age'] < age_cutoff else 151\n",
    "    return row['lipase_level'] >= 3 * upper_limit\n",
    "\n",
    "# Step 8: Filter to include only records with high lipase levels\n",
    "high_lipase_df = lipase_values_df[lipase_values_df.apply(check_high_lipase, axis=1)].copy()\n",
    "\n",
    "\n",
    "# Step 9: Sort and retain the earliest record for each subject_id and hadm_id combination\n",
    "high_lipase_df = high_lipase_df.sort_values(by=['subject_id', 'hadm_id', 'charttime']).drop_duplicates(\n",
    "    subset=['subject_id', 'hadm_id'], keep='first'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "Tc3SXPkra0Gq",
    "outputId": "ee86788e-544a-488d-c8e9-5b282ac175ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       subject_id   hadm_id           charttime  lipase_level  \\\n",
      "1        10004606  29242151 2159-02-20 18:30:00        1222.0   \n",
      "17547    10006431  24638489 2129-01-23 23:36:00         508.0   \n",
      "15       10017531  22580355 2159-09-22 20:56:00        1164.0   \n",
      "17804    10021357  25937617 2144-12-30 06:55:00        1249.0   \n",
      "55       10036086  28728587 2196-05-26 09:25:00         677.0   \n",
      "\n",
      "                admittime           dischtime gender  \\\n",
      "1     2159-02-20 13:43:00 2159-03-06 16:51:00      F   \n",
      "17547 2129-01-24 01:08:00 2129-01-30 16:50:00      F   \n",
      "15    2159-09-22 19:30:00 2159-10-24 13:40:00      M   \n",
      "17804 2144-12-27 19:41:00 2145-01-04 19:54:00      F   \n",
      "55    2196-05-20 02:47:00 2196-06-12 11:42:00      M   \n",
      "\n",
      "       approximate_age_at_admission   race  actual_age  in_hospital_death  \\\n",
      "1                                64  WHITE          64              False   \n",
      "17547                            66  WHITE          67              False   \n",
      "15                               63  WHITE          64              False   \n",
      "17804                            91  WHITE          91              False   \n",
      "55                               57  WHITE          58              False   \n",
      "\n",
      "       length_of_stay  \n",
      "1           14.130556  \n",
      "17547        6.654167  \n",
      "15          31.756944  \n",
      "17804        8.009028  \n",
      "55          23.371528  \n",
      "Number of high lipase cases: 2299\n",
      "Number of unique patients with high lipase levels: 2104\n"
     ]
    }
   ],
   "source": [
    "# Display results\n",
    "print(high_lipase_df.head())\n",
    "print(f\"Number of high lipase cases: {high_lipase_df.shape[0]}\")\n",
    "print(f\"Number of unique patients with high lipase levels: {high_lipase_df['subject_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a CSV file with the high lipase cases\n",
    "high_lipase_df.to_csv('high_lipase_cases.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhuyu/anaconda3/envs/COMP90089/lib/python3.12/site-packages/google/cloud/bigquery/table.py:1727: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amylase Items in hosp:\n",
      "    itemid                            label                fluid\n",
      "0    50867                          Amylase                Blood\n",
      "1    53087                          Amylase                Blood\n",
      "2    51930                   Amylase, Stool                Stool\n",
      "3    51072                   Amylase, Urine                Urine\n",
      "4    51073  Amylase/Creatinine Ratio, Urine                Urine\n",
      "5    51963     Amylase/Creatinine Clearance                Urine\n",
      "6    51964                   Amylase, Serum                Urine\n",
      "7    51999                    Urine Amylase                Urine\n",
      "8    50836                 Amylase, Ascites              Ascites\n",
      "9    51047                 Amylase, Pleural              Pleural\n",
      "10   51020             Amylase, Joint Fluid          Joint Fluid\n",
      "11   51026              Amylase, Body Fluid     Other Body Fluid\n",
      "12   51780                     Amylase, CSF  Cerebrospinal Fluid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhuyu/anaconda3/envs/COMP90089/lib/python3.12/site-packages/google/cloud/bigquery/table.py:1727: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amylase Items in icu:\n",
      "   itemid    label category\n",
      "0  220581  Amylase     Labs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhuyu/anaconda3/envs/COMP90089/lib/python3.12/site-packages/google/cloud/bigquery/table.py:1727: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      subject_id   hadm_id           charttime  amylase_level\n",
      "767     10112484      <NA> 2124-05-30 07:10:00         2173.0\n",
      "1087    10149959  24022109 2144-11-28 09:15:00         1056.0\n",
      "1094    10150465      <NA> 2153-08-23 12:36:00         1601.0\n",
      "1560    10219697      <NA> 2114-09-17 11:29:00         2219.0\n",
      "1852    10246974  22572693 2127-10-20 06:50:00         1005.0\n",
      "Number of high amylase cases: 332\n",
      "Number of unique patients with high amylase levels: 303\n"
     ]
    }
   ],
   "source": [
    "# 3. Get high amylase level patients\n",
    "# 3. Get high amylase level patients\n",
    "\n",
    "# Step 1: Retrieve Amylase Item IDs for both hosp and ICU\n",
    "amylase_item_query_hosp = \"\"\"\n",
    "SELECT itemid, label, fluid\n",
    "FROM `physionet-data.mimiciv_hosp.d_labitems`\n",
    "WHERE LOWER(label) LIKE '%amylase%'\n",
    "\"\"\"\n",
    "amylase_items_df_hosp = run_query(amylase_item_query_hosp)\n",
    "print(\"Amylase Items in hosp:\")\n",
    "print(amylase_items_df_hosp)\n",
    "\n",
    "amylase_item_query_icu = \"\"\"\n",
    "SELECT itemid, label, category\n",
    "FROM `physionet-data.mimiciv_icu.d_items`\n",
    "WHERE LOWER(label) LIKE '%amylase%'\n",
    "\"\"\"\n",
    "amylase_items_df_icu = run_query(amylase_item_query_icu)\n",
    "print(\"Amylase Items in icu:\")\n",
    "print(amylase_items_df_icu)\n",
    "\n",
    "# Identified Amylase item IDs for both hosp and ICU\n",
    "amylase_itemids = [50867, 53087, 51964, 220581]\n",
    "\n",
    "# Step 2: Retrieve Amylase Values from hosp\n",
    "amylase_values_query_hosp = f\"\"\"\n",
    "SELECT subject_id, hadm_id, charttime, valuenum AS amylase_level\n",
    "FROM `physionet-data.mimiciv_hosp.labevents`\n",
    "WHERE itemid IN ({', '.join(map(str, amylase_itemids))})\n",
    "ORDER BY subject_id, charttime\n",
    "\"\"\"\n",
    "amylase_values_df_hosp = run_query(amylase_values_query_hosp)\n",
    "\n",
    "# Step 3: Retrieve Amylase Values from ICU\n",
    "amylase_values_query_icu = f\"\"\"\n",
    "SELECT subject_id, hadm_id, charttime, valuenum AS amylase_level\n",
    "FROM `physionet-data.mimiciv_icu.chartevents`\n",
    "WHERE itemid IN ({', '.join(map(str, amylase_itemids))})\n",
    "ORDER BY subject_id, charttime\n",
    "\"\"\"\n",
    "amylase_values_df_icu = run_query(amylase_values_query_icu)\n",
    "\n",
    "# Step 4: Concatenate ICU and hosp data\n",
    "amylase_values_df = pd.concat([amylase_values_df_hosp, amylase_values_df_icu], ignore_index=True)\n",
    "\n",
    "# Step 5: Filter to include only records with amylase levels > 1000\n",
    "amylase_critical_df = amylase_values_df[amylase_values_df['amylase_level'] > 1000]\n",
    "\n",
    "# Step 6: Sort and retain the earliest record for each subject_id and hadm_id\n",
    "amylase_critical_df = amylase_critical_df.sort_values(by=['subject_id', 'hadm_id', 'charttime']).drop_duplicates(\n",
    "    subset=['subject_id', 'hadm_id'], keep='first'\n",
    ")\n",
    "\n",
    "# Count number of unique patients with high amylase levels\n",
    "num_patients = amylase_critical_df['subject_id'].nunique()\n",
    "print(amylase_critical_df.head())\n",
    "print(f\"Number of high amylase cases: {amylase_critical_df.shape[0]}\")\n",
    "print(f\"Number of unique patients with high amylase levels: {num_patients}\")\n",
    "\n",
    "# Step 7: Inner join high Amylase level records with high Lipase level records\n",
    "hl_ha_df = pd.merge(\n",
    "    high_lipase_df.copy(),\n",
    "    amylase_critical_df[['subject_id', 'hadm_id', 'amylase_level']],\n",
    "    on=['subject_id', 'hadm_id'],\n",
    "    how='outer',\n",
    "    suffixes=('_lipase', '_amylase')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   subject_id   hadm_id           charttime  lipase_level           admittime  \\\n",
      "0    10004606  29242151 2159-02-20 18:30:00        1222.0 2159-02-20 13:43:00   \n",
      "1    10006431  24638489 2129-01-23 23:36:00         508.0 2129-01-24 01:08:00   \n",
      "2    10017531  22580355 2159-09-22 20:56:00        1164.0 2159-09-22 19:30:00   \n",
      "3    10021357  25937617 2144-12-30 06:55:00        1249.0 2144-12-27 19:41:00   \n",
      "4    10036086  28728587 2196-05-26 09:25:00         677.0 2196-05-20 02:47:00   \n",
      "\n",
      "            dischtime gender  approximate_age_at_admission   race  actual_age  \\\n",
      "0 2159-03-06 16:51:00      F                            64  WHITE          64   \n",
      "1 2129-01-30 16:50:00      F                            66  WHITE          67   \n",
      "2 2159-10-24 13:40:00      M                            63  WHITE          64   \n",
      "3 2145-01-04 19:54:00      F                            91  WHITE          91   \n",
      "4 2196-06-12 11:42:00      M                            57  WHITE          58   \n",
      "\n",
      "   in_hospital_death  length_of_stay  amylase_level  \n",
      "0              False       14.130556            NaN  \n",
      "1              False        6.654167            NaN  \n",
      "2              False       31.756944            NaN  \n",
      "3              False        8.009028            NaN  \n",
      "4              False       23.371528            NaN  \n",
      "Number of rows in the combined dataset with high lipase or high amylase levels: 2423\n",
      "Number of unique patients in the combined dataset with high lipase or high amylase levels: 2173\n"
     ]
    }
   ],
   "source": [
    "# Display the combined dataset\n",
    "print(hl_ha_df.head())\n",
    "print(f\"Number of rows in the combined dataset with high lipase or high amylase levels: {hl_ha_df.shape[0]}\")\n",
    "print(f\"Number of unique patients in the combined dataset with high lipase or high amylase levels: {hl_ha_df['subject_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhuyu/anaconda3/envs/COMP90089/lib/python3.12/site-packages/google/cloud/bigquery/table.py:1727: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRP Items in hosp:\n",
      "    itemid                       label                fluid\n",
      "0    50864           Alpha-Fetoprotein                Blood\n",
      "1    50889          C-Reactive Protein                Blood\n",
      "2    50975     Protein Electrophoresis                Blood\n",
      "3    50976              Protein, Total                Blood\n",
      "4    53096              Protein, Total                Blood\n",
      "5    51949        Total Protein, Stool                Stool\n",
      "6    51068               24 hr Protein                Urine\n",
      "7    51099    Protein/Creatinine Ratio                Urine\n",
      "8    51102        Total Protein, Urine                Urine\n",
      "9    51992                     Protein                Urine\n",
      "10   50849      Total Protein, Ascites              Ascites\n",
      "11   51059      Total Protein, Pleural              Pleural\n",
      "12   51024  Total Protein, Joint Fluid          Joint Fluid\n",
      "13   51043   Total Protein, Body Fluid     Other Body Fluid\n",
      "14   51802          Total Protein, CSF  Cerebrospinal Fluid\n",
      "15   51270          Protein C, Antigen                Blood\n",
      "16   51271       Protein C, Functional                Blood\n",
      "17   51272          Protein S, Antigen                Blood\n",
      "18   51273       Protein S, Functional                Blood\n",
      "19   52162                   Protein S                Blood\n",
      "20   51492                     Protein                Urine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhuyu/anaconda3/envs/COMP90089/lib/python3.12/site-packages/google/cloud/bigquery/table.py:1727: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRP Items in icu:\n",
      "   itemid                       label                 category\n",
      "0  229583                Beneprotein.  Nutrition - Supplements\n",
      "1  220454                     Protein              Ingredients\n",
      "2  220612   ZC Reactive Protein (CRP)                     Labs\n",
      "3  220650               Total Protein                     Labs\n",
      "4  227444    C Reactive Protein (CRP)                     Labs\n",
      "5  226184  Estimated Protein Needs/Kg                  General\n",
      "6  225970                 Beneprotein      Nutrition - Enteral\n",
      "7  229296   Vital High Protein (Full)      Nutrition - Enteral\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhuyu/anaconda3/envs/COMP90089/lib/python3.12/site-packages/google/cloud/bigquery/table.py:1727: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique patients with high CRP levels within 48 hrs: 1830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5w/c5jgggvd3f52shk667p25scc0000gn/T/ipykernel_54451/155219287.py:43: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  crp_values_df = pd.concat([crp_values_df_hosp, crp_values_df_icu], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# 4. Get high CRP level patients\n",
    "# Step 1: Retrieve CRP Item IDs for both hosp and ICU\n",
    "crp_item_query_hosp = \"\"\"\n",
    "SELECT itemid, label, fluid\n",
    "FROM `physionet-data.mimiciv_hosp.d_labitems`\n",
    "WHERE LOWER(label) LIKE '%c-reactive%' or LOWER(label) LIKE '%protein%'\n",
    "\"\"\"\n",
    "crp_items_df_hosp = run_query(crp_item_query_hosp)\n",
    "print(\"CRP Items in hosp:\")\n",
    "print(crp_items_df_hosp)\n",
    "\n",
    "crp_item_query_icu = \"\"\"\n",
    "SELECT itemid, label, category\n",
    "FROM `physionet-data.mimiciv_icu.d_items`\n",
    "WHERE LOWER(label) LIKE '%c-reactive%' or LOWER(label) LIKE '%protein%'\n",
    "\"\"\"\n",
    "crp_items_df_icu = run_query(crp_item_query_icu)\n",
    "print(\"CRP Items in icu:\")\n",
    "print(crp_items_df_icu)\n",
    "\n",
    "crp_itemid_hosp = \"50889\"\n",
    "crp_itemid_icu = \"51006\"\n",
    "\n",
    "# Step 2: Retrieve CRP values from hosp\n",
    "crp_values_query_hosp = f\"\"\"\n",
    "SELECT subject_id, hadm_id, charttime, valuenum AS crp_level\n",
    "FROM `physionet-data.mimiciv_hosp.labevents`\n",
    "WHERE itemid IN ({crp_itemid_hosp})\n",
    "ORDER BY subject_id, charttime\n",
    "\"\"\"\n",
    "crp_values_df_hosp = run_query(crp_values_query_hosp)\n",
    "\n",
    "# Step 3: Retrieve CRP values from icu\n",
    "crp_values_query_icu = f\"\"\"\n",
    "SELECT subject_id, hadm_id, charttime, valuenum AS crp_level\n",
    "FROM `physionet-data.mimiciv_icu.chartevents`\n",
    "WHERE itemid IN ({crp_itemid_icu})\n",
    "ORDER BY subject_id, charttime\n",
    "\"\"\"\n",
    "crp_values_df_icu = run_query(crp_values_query_icu)\n",
    "\n",
    "# Step 4: Concatenate ICU and hosp data and filter for first 48 hours after admission\n",
    "crp_values_df = pd.concat([crp_values_df_hosp, crp_values_df_icu], ignore_index=True)\n",
    "crp_values_df = pd.merge(crp_values_df, patient_info_df[['subject_id', 'hadm_id', 'admittime']], on=['subject_id', 'hadm_id'])\n",
    "\n",
    "# Convert timestamps\n",
    "crp_values_df['charttime'] = pd.to_datetime(crp_values_df['charttime'])\n",
    "crp_values_df['admittime'] = pd.to_datetime(crp_values_df['admittime'])\n",
    "\n",
    "# Filter for entries within the first 48 hours after admission\n",
    "crp_values_df = crp_values_df[(crp_values_df['charttime'] - crp_values_df['admittime']).dt.total_seconds() / (60 * 60) <= 48]\n",
    "\n",
    "# Group by subject_id and hadm_id, and take the maximum CRP level within 48 hours\n",
    "crp_values_df = crp_values_df.groupby(['subject_id', 'hadm_id']).agg(\n",
    "    crp_level=('crp_level', 'max')\n",
    ").reset_index()\n",
    "\n",
    "# Now `crp_values_df` has the maximum CRP levels within the first 48 hours for each patient-admission\n",
    "# Step 6: Filter records with CRP > 150 mg/dL (optional, since you may already have this filter)\n",
    "crp_critical_df = crp_values_df[crp_values_df['crp_level'] > 150]\n",
    "\n",
    "# Count the number of unique patients with high CRP levels\n",
    "num_patients = crp_critical_df['subject_id'].nunique()\n",
    "print(f\"Number of unique patients with high CRP levels within 48 hrs: {num_patients}\")\n",
    "\n",
    "# Outer join CRP critical data with the existing combined dataset\n",
    "hl_ha_hc_df = pd.merge(\n",
    "    hl_ha_df.copy(),\n",
    "    crp_critical_df[['subject_id', 'hadm_id', 'crp_level']],\n",
    "    on=['subject_id', 'hadm_id'],\n",
    "    how='outer',\n",
    "    suffixes=('', '_crp')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "hl_ha_hc_df.set_index(['subject_id', 'hadm_id'], inplace=True)\n",
    "hl_ha_hc_df.update(patient_info_df.set_index(['subject_id', 'hadm_id']))\n",
    "hl_ha_hc_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   subject_id   hadm_id           charttime  lipase_level           admittime  \\\n",
      "0    10002976  27179825                 NaT           NaN 2145-02-28 19:44:00   \n",
      "1    10003400  23559586                 NaT           NaN 2137-08-04 00:07:00   \n",
      "2    10004606  29242151 2159-02-20 18:30:00        1222.0 2159-02-20 13:43:00   \n",
      "3    10006431  24638489 2129-01-23 23:36:00         508.0 2129-01-24 01:08:00   \n",
      "4    10006513  29846618                 NaT           NaN 2127-03-27 14:52:00   \n",
      "\n",
      "            dischtime gender  approximate_age_at_admission  \\\n",
      "0 2145-03-05 16:45:00      M                            70   \n",
      "1 2137-09-02 17:05:00      F                            72   \n",
      "2 2159-03-06 16:51:00      F                            64   \n",
      "3 2129-01-30 16:50:00      F                            66   \n",
      "4 2127-03-28 15:20:00      M                            42   \n",
      "\n",
      "                     race  actual_age  in_hospital_death  length_of_stay  \\\n",
      "0                   WHITE          71              False        4.875694   \n",
      "1  BLACK/AFRICAN AMERICAN          75               True       29.706944   \n",
      "2                   WHITE          64              False       14.130556   \n",
      "3                   WHITE          67              False        6.654167   \n",
      "4                   OTHER          51              False        1.019444   \n",
      "\n",
      "   amylase_level  crp_level  \n",
      "0            NaN      243.8  \n",
      "1            NaN      156.2  \n",
      "2            NaN        NaN  \n",
      "3            NaN        NaN  \n",
      "4            NaN      253.0  \n",
      "Number of rows in the combined dataset with high lipase or high amylase or high CRP levels: 4357\n",
      "Number of unique patients in the combined dataset with high lipase or high amylase or high CRP levels: 3955\n"
     ]
    }
   ],
   "source": [
    "# Display the combined dataset\n",
    "print(hl_ha_hc_df.head())\n",
    "print(f\"Number of rows in the combined dataset with high lipase or high amylase or high CRP levels: {hl_ha_hc_df.shape[0]}\")\n",
    "print(f\"Number of unique patients in the combined dataset with high lipase or high amylase or high CRP levels: {hl_ha_hc_df['subject_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique patients with all three levels present: 1\n",
      "Number of rows with all three levels present: 1\n"
     ]
    }
   ],
   "source": [
    "# Filter the dataset to include only rows where all three levels are not NaN\n",
    "non_nan_levels_df = hl_ha_hc_df.dropna(subset=['crp_level', 'lipase_level', 'amylase_level'])\n",
    "\n",
    "# Count the number of unique patients with all three levels present\n",
    "num_patients_with_all_levels = non_nan_levels_df['subject_id'].nunique()\n",
    "print(f\"Number of unique patients with all three levels present: {num_patients_with_all_levels}\")\n",
    "\n",
    "# Count the number of rows with all three levels present\n",
    "num_rows_with_all_levels = non_nan_levels_df.shape[0]\n",
    "print(f\"Number of rows with all three levels present: {num_rows_with_all_levels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gdg0qCPfW6WG",
    "outputId": "cef577a8-24f4-4118-ec8f-00c02e10c8f5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhuyu/anaconda3/envs/COMP90089/lib/python3.12/site-packages/google/cloud/bigquery/table.py:1727: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   subject_id   hadm_id           charttime  lipase_level           admittime  \\\n",
      "0    10002976  27179825                 NaT           NaN 2145-02-28 19:44:00   \n",
      "1    10003400  23559586                 NaT           NaN 2137-08-04 00:07:00   \n",
      "2    10004606  29242151 2159-02-20 18:30:00        1222.0 2159-02-20 13:43:00   \n",
      "3    10006431  24638489 2129-01-23 23:36:00         508.0 2129-01-24 01:08:00   \n",
      "4    10006513  29846618                 NaT           NaN 2127-03-27 14:52:00   \n",
      "\n",
      "            dischtime gender  approximate_age_at_admission  \\\n",
      "0 2145-03-05 16:45:00      M                            70   \n",
      "1 2137-09-02 17:05:00      F                            72   \n",
      "2 2159-03-06 16:51:00      F                            64   \n",
      "3 2129-01-30 16:50:00      F                            66   \n",
      "4 2127-03-28 15:20:00      M                            42   \n",
      "\n",
      "                     race  actual_age  in_hospital_death  length_of_stay  \\\n",
      "0                   WHITE          71              False        4.875694   \n",
      "1  BLACK/AFRICAN AMERICAN          75               True       29.706944   \n",
      "2                   WHITE          64              False       14.130556   \n",
      "3                   WHITE          67              False        6.654167   \n",
      "4                   OTHER          51              False        1.019444   \n",
      "\n",
      "   amylase_level  crp_level icd_code  is_confirmed_ap  \n",
      "0            NaN      243.8      NaN            False  \n",
      "1            NaN      156.2      NaN            False  \n",
      "2            NaN        NaN    K8510             True  \n",
      "3            NaN        NaN    K8580             True  \n",
      "4            NaN      253.0      NaN            False  \n",
      "Number of unique patients with high levels who are confirmed with AP: 1375\n",
      "Number of rows in the combined dataset with AP confirmation: 4357\n"
     ]
    }
   ],
   "source": [
    "# 5. Get AP ICD Info\n",
    "# Step 1: Retrieve records with AP diagnosis based on ICD codes\n",
    "ap_icd_query = f\"\"\"\n",
    "SELECT subject_id, hadm_id, icd_code, seq_num \n",
    "FROM `physionet-data.mimiciv_hosp.diagnoses_icd`\n",
    "WHERE icd_code LIKE 'K85%' OR icd_code = '5770'\n",
    "ORDER BY subject_id, seq_num\n",
    "\"\"\"\n",
    "ap_icd_df = run_query(ap_icd_query)\n",
    "\n",
    "# Keep only the first record for each patient\n",
    "ap_icd_df = ap_icd_df.drop_duplicates(subset=['subject_id', 'hadm_id'], keep='first')\n",
    "\n",
    "# Step 2: Merge AP diagnosis info with the existing combined dataset\n",
    "combined_df_with_ap = pd.merge(\n",
    "    hl_ha_hc_df.copy(),\n",
    "    ap_icd_df[['subject_id', 'hadm_id', 'icd_code']],\n",
    "    on=['subject_id', 'hadm_id'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Step 3: Label records with AP confirmation\n",
    "combined_df_with_ap['is_confirmed_ap'] = combined_df_with_ap['icd_code'].notna()\n",
    "\n",
    "# Display the resulting dataset\n",
    "print(combined_df_with_ap.head())\n",
    "\n",
    "# Count unique patients confirmed with AP\n",
    "num_confirmed_ap_patients = combined_df_with_ap[combined_df_with_ap['is_confirmed_ap'] == True]['subject_id'].nunique()\n",
    "print(f\"Number of unique patients with high levels who are confirmed with AP: {num_confirmed_ap_patients}\")\n",
    "\n",
    "# Total number of rows in the combined dataset with AP confirmation\n",
    "num_rows = combined_df_with_ap.shape[0]\n",
    "print(f\"Number of rows in the combined dataset with AP confirmation: {num_rows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "zOsCYBjQ8I-n"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhuyu/anaconda3/envs/COMP90089/lib/python3.12/site-packages/google/cloud/bigquery/table.py:1727: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   subject_id   hadm_id           charttime  lipase_level           admittime  \\\n",
      "0    10002976  27179825                 NaT           NaN 2145-02-28 19:44:00   \n",
      "1    10003400  23559586                 NaT           NaN 2137-08-04 00:07:00   \n",
      "2    10004606  29242151 2159-02-20 18:30:00        1222.0 2159-02-20 13:43:00   \n",
      "3    10006431  24638489 2129-01-23 23:36:00         508.0 2129-01-24 01:08:00   \n",
      "4    10006513  29846618                 NaT           NaN 2127-03-27 14:52:00   \n",
      "\n",
      "            dischtime gender  approximate_age_at_admission  \\\n",
      "0 2145-03-05 16:45:00      M                            70   \n",
      "1 2137-09-02 17:05:00      F                            72   \n",
      "2 2159-03-06 16:51:00      F                            64   \n",
      "3 2129-01-30 16:50:00      F                            66   \n",
      "4 2127-03-28 15:20:00      M                            42   \n",
      "\n",
      "                     race  actual_age  in_hospital_death  length_of_stay  \\\n",
      "0                   WHITE          71              False        4.875694   \n",
      "1  BLACK/AFRICAN AMERICAN          75               True       29.706944   \n",
      "2                   WHITE          64              False       14.130556   \n",
      "3                   WHITE          67              False        6.654167   \n",
      "4                   OTHER          51              False        1.019444   \n",
      "\n",
      "   amylase_level  crp_level icd_code  is_confirmed_ap  average_weight  \n",
      "0            NaN      243.8      NaN            False             NaN  \n",
      "1            NaN      156.2      NaN            False      104.366667  \n",
      "2            NaN        NaN    K8510             True       56.300000  \n",
      "3            NaN        NaN    K8580             True             NaN  \n",
      "4            NaN      253.0      NaN            False             NaN  \n",
      "Number of rows with average weight data: 4357\n"
     ]
    }
   ],
   "source": [
    "# 6. Get Weight Info\n",
    "# Step 1: Retrieve weight data for ICU patients (only admit and daily weight)\n",
    "weight_query = \"\"\"\n",
    "SELECT\n",
    "    subject_id, hadm_id, stay_id, charttime,\n",
    "    CASE WHEN itemid = 226512 THEN 'admit' ELSE 'daily' END AS weight_type,\n",
    "    valuenum AS weight\n",
    "FROM `physionet-data.mimiciv_icu.chartevents`\n",
    "WHERE valuenum IS NOT NULL\n",
    "  AND itemid IN (226512, 224639)  -- Admit Weight and Daily Weight\n",
    "  AND valuenum > 0\n",
    "ORDER BY subject_id, charttime\n",
    "\"\"\"\n",
    "\n",
    "# Step 2: Run the query to retrieve weight data\n",
    "weight_df = run_query(weight_query)\n",
    "\n",
    "# Step 3: Calculate the average weight per patient (admit and daily weights)\n",
    "# Group by patient identifiers and calculate the mean weight\n",
    "average_weight_df = weight_df.groupby(['subject_id', 'hadm_id']).agg(\n",
    "    average_weight=('weight', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "# Step 4: Merge the average weight data with the main combined dataset\n",
    "combined_df_with_avg_weight = pd.merge(\n",
    "    combined_df_with_ap.copy(),\n",
    "    average_weight_df[['subject_id', 'hadm_id', 'average_weight']],\n",
    "    on=['subject_id', 'hadm_id'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(combined_df_with_avg_weight.head())\n",
    "print(f\"Number of rows with average weight data: {combined_df_with_avg_weight.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhuyu/anaconda3/envs/COMP90089/lib/python3.12/site-packages/google/cloud/bigquery/table.py:1727: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   subject_id   hadm_id           charttime  lipase_level           admittime  \\\n",
      "0    10002976  27179825                 NaT           NaN 2145-02-28 19:44:00   \n",
      "1    10003400  23559586                 NaT           NaN 2137-08-04 00:07:00   \n",
      "2    10004606  29242151 2159-02-20 18:30:00        1222.0 2159-02-20 13:43:00   \n",
      "3    10006431  24638489 2129-01-23 23:36:00         508.0 2129-01-24 01:08:00   \n",
      "4    10006513  29846618                 NaT           NaN 2127-03-27 14:52:00   \n",
      "\n",
      "            dischtime gender  approximate_age_at_admission  \\\n",
      "0 2145-03-05 16:45:00      M                            70   \n",
      "1 2137-09-02 17:05:00      F                            72   \n",
      "2 2159-03-06 16:51:00      F                            64   \n",
      "3 2129-01-30 16:50:00      F                            66   \n",
      "4 2127-03-28 15:20:00      M                            42   \n",
      "\n",
      "                     race  actual_age  in_hospital_death  length_of_stay  \\\n",
      "0                   WHITE          71              False        4.875694   \n",
      "1  BLACK/AFRICAN AMERICAN          75               True       29.706944   \n",
      "2                   WHITE          64              False       14.130556   \n",
      "3                   WHITE          67              False        6.654167   \n",
      "4                   OTHER          51              False        1.019444   \n",
      "\n",
      "   amylase_level  crp_level icd_code  is_confirmed_ap  average_weight  \\\n",
      "0            NaN      243.8      NaN            False             NaN   \n",
      "1            NaN      156.2      NaN            False      104.366667   \n",
      "2            NaN        NaN    K8510             True       56.300000   \n",
      "3            NaN        NaN    K8580             True             NaN   \n",
      "4            NaN      253.0      NaN            False             NaN   \n",
      "\n",
      "   charlson_comorbidity_index  \n",
      "0                           5  \n",
      "1                           5  \n",
      "2                           4  \n",
      "3                           3  \n",
      "4                           2  \n",
      "Number of rows in the combined dataset with CCI: 4357\n"
     ]
    }
   ],
   "source": [
    "# 7. Get CCI Info\n",
    "# Step 1: Query for Charlson Comorbidity Index (CCI) based on ICD codes\n",
    "cci_query = \"\"\"\n",
    "WITH diag AS (\n",
    "    SELECT \n",
    "        hadm_id,\n",
    "        CASE WHEN icd_version = 9 THEN icd_code ELSE NULL END AS icd9_code,\n",
    "        CASE WHEN icd_version = 10 THEN icd_code ELSE NULL END AS icd10_code\n",
    "    FROM `physionet-data.mimiciv_hosp.diagnoses_icd`\n",
    "),\n",
    "com AS (\n",
    "    SELECT ad.hadm_id,\n",
    "        -- Myocardial infarction\n",
    "        MAX(CASE WHEN SUBSTR(icd9_code, 1, 3) IN ('410','412') OR SUBSTR(icd10_code, 1, 3) IN ('I21','I22') OR SUBSTR(icd10_code, 1, 4) = 'I252' THEN 1 ELSE 0 END) AS myocardial_infarct,\n",
    "        -- Congestive heart failure\n",
    "        MAX(CASE WHEN SUBSTR(icd9_code, 1, 3) = '428' OR SUBSTR(icd9_code, 1, 5) IN ('39891','40201','40211','40291','40401','40403','40411','40413','40491','40493') OR SUBSTR(icd9_code, 1, 4) BETWEEN '4254' AND '4259' OR SUBSTR(icd10_code, 1, 3) IN ('I43','I50') OR SUBSTR(icd10_code, 1, 4) IN ('I099','I110','I130','I132','I255','I420','I425','I426','I427','I428','I429','P290') THEN 1 ELSE 0 END) AS congestive_heart_failure,\n",
    "        -- Peripheral vascular disease\n",
    "        MAX(CASE WHEN SUBSTR(icd9_code, 1, 3) IN ('440','441') OR SUBSTR(icd9_code, 1, 4) IN ('0930','4373','4471','5571','5579','V434') OR SUBSTR(icd9_code, 1, 4) BETWEEN '4431' AND '4439' OR SUBSTR(icd10_code, 1, 3) IN ('I70','I71') OR SUBSTR(icd10_code, 1, 4) IN ('I731','I738','I739','I771','I790','I792','K551','K558','K559','Z958','Z959') THEN 1 ELSE 0 END) AS peripheral_vascular_disease,\n",
    "        -- Additional comorbidity definitions (Cerebrovascular disease, Dementia, Chronic pulmonary disease, etc.)\n",
    "        -- Add other conditions following similar MAX/CASE structure as above for each comorbidity\n",
    "    FROM `physionet-data.mimiciv_hosp.admissions` ad\n",
    "    LEFT JOIN diag ON ad.hadm_id = diag.hadm_id\n",
    "    GROUP BY ad.hadm_id\n",
    "),\n",
    "ag AS (\n",
    "    SELECT \n",
    "        hadm_id,\n",
    "        age,\n",
    "        CASE WHEN age <= 40 THEN 0 WHEN age <= 50 THEN 1 WHEN age <= 60 THEN 2 WHEN age <= 70 THEN 3 ELSE 4 END AS age_score\n",
    "    FROM `physionet-data.mimiciv_derived.age`\n",
    ")\n",
    "SELECT \n",
    "    ad.subject_id,\n",
    "    ad.hadm_id,\n",
    "    ag.age_score,\n",
    "    myocardial_infarct,\n",
    "    congestive_heart_failure,\n",
    "    peripheral_vascular_disease,\n",
    "    -- Include all other comorbidities fields here...\n",
    "    age_score + myocardial_infarct + congestive_heart_failure + peripheral_vascular_disease\n",
    "    -- + add all the weighted conditions here as in your full CCI calculation\n",
    "    AS charlson_comorbidity_index\n",
    "FROM `physionet-data.mimiciv_hosp.admissions` ad\n",
    "LEFT JOIN com ON ad.hadm_id = com.hadm_id\n",
    "LEFT JOIN ag ON com.hadm_id = ag.hadm_id\n",
    "\"\"\"\n",
    "\n",
    "# Step 2: Run the query to get CCI data\n",
    "cci_df = run_query(cci_query)\n",
    "\n",
    "# Step 3: Merge CCI data with the main dataset based on `subject_id` and `hadm_id`\n",
    "combined_df_with_ap = pd.merge(\n",
    "    combined_df_with_avg_weight.copy(),\n",
    "    cci_df[['subject_id', 'hadm_id', 'charlson_comorbidity_index']],\n",
    "    on=['subject_id', 'hadm_id'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Step 4: Display the final combined dataset with CCI information\n",
    "print(combined_df_with_ap.head())\n",
    "print(f\"Number of rows in the combined dataset with CCI: {combined_df_with_ap.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhuyu/anaconda3/envs/COMP90089/lib/python3.12/site-packages/google/cloud/bigquery/table.py:1727: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   subject_id   hadm_id           charttime  lipase_level           admittime  \\\n",
      "0    10002976  27179825                 NaT           NaN 2145-02-28 19:44:00   \n",
      "1    10003400  23559586                 NaT           NaN 2137-08-04 00:07:00   \n",
      "2    10004606  29242151 2159-02-20 18:30:00        1222.0 2159-02-20 13:43:00   \n",
      "3    10006431  24638489 2129-01-23 23:36:00         508.0 2129-01-24 01:08:00   \n",
      "4    10006513  29846618                 NaT           NaN 2127-03-27 14:52:00   \n",
      "\n",
      "            dischtime gender  approximate_age_at_admission  \\\n",
      "0 2145-03-05 16:45:00      M                            70   \n",
      "1 2137-09-02 17:05:00      F                            72   \n",
      "2 2159-03-06 16:51:00      F                            64   \n",
      "3 2129-01-30 16:50:00      F                            66   \n",
      "4 2127-03-28 15:20:00      M                            42   \n",
      "\n",
      "                     race  actual_age  in_hospital_death  length_of_stay  \\\n",
      "0                   WHITE          71              False        4.875694   \n",
      "1  BLACK/AFRICAN AMERICAN          75               True       29.706944   \n",
      "2                   WHITE          64              False       14.130556   \n",
      "3                   WHITE          67              False        6.654167   \n",
      "4                   OTHER          51              False        1.019444   \n",
      "\n",
      "   amylase_level  crp_level icd_code  is_confirmed_ap  average_weight  \\\n",
      "0            NaN      243.8      NaN            False             NaN   \n",
      "1            NaN      156.2      NaN            False      104.366667   \n",
      "2            NaN        NaN    K8510             True       56.300000   \n",
      "3            NaN        NaN    K8580             True             NaN   \n",
      "4            NaN      253.0      NaN            False             NaN   \n",
      "\n",
      "   charlson_comorbidity_index  average_height  \n",
      "0                           5             NaN  \n",
      "1                           5           165.0  \n",
      "2                           4           163.0  \n",
      "3                           3             NaN  \n",
      "4                           2             NaN  \n",
      "Number of rows with average height data: 4357\n"
     ]
    }
   ],
   "source": [
    "# 8. Get Height info\n",
    "# 1. Get height data for ICU patients (in both inches and centimeters)\n",
    "height_query = \"\"\"\n",
    "WITH ht_in AS (\n",
    "  SELECT \n",
    "    c.subject_id, c.hadm_id, c.stay_id, c.charttime,\n",
    "    -- Convert height from inches to centimeters\n",
    "    ROUND(c.valuenum * 2.54, 2) AS height\n",
    "  FROM `physionet-data.mimiciv_icu.chartevents` c\n",
    "  WHERE c.valuenum IS NOT NULL\n",
    "    AND c.itemid = 226707  -- Height in inches\n",
    "),\n",
    "ht_cm AS (\n",
    "  SELECT \n",
    "    c.subject_id, c.hadm_id, c.stay_id, c.charttime,\n",
    "    ROUND(c.valuenum, 2) AS height\n",
    "  FROM `physionet-data.mimiciv_icu.chartevents` c\n",
    "  WHERE c.valuenum IS NOT NULL\n",
    "    AND c.itemid = 226730  -- Height in centimeters\n",
    "),\n",
    "-- Merge heights from both inches and centimeters, taking one per charted row\n",
    "ht_stg0 AS (\n",
    "  SELECT\n",
    "    COALESCE(h1.subject_id, h2.subject_id) AS subject_id,\n",
    "    COALESCE(h1.hadm_id, h2.hadm_id) AS hadm_id,\n",
    "    COALESCE(h1.stay_id, h2.stay_id) AS stay_id,\n",
    "    COALESCE(h1.charttime, h2.charttime) AS charttime,\n",
    "    COALESCE(h1.height, h2.height) AS height\n",
    "  FROM ht_cm h1\n",
    "  FULL OUTER JOIN ht_in h2\n",
    "    ON h1.subject_id = h2.subject_id\n",
    "    AND h1.hadm_id = h2.hadm_id\n",
    "    AND h1.charttime = h2.charttime\n",
    ")\n",
    "SELECT subject_id, hadm_id, stay_id, charttime, height\n",
    "FROM ht_stg0\n",
    "WHERE height IS NOT NULL\n",
    "  AND height BETWEEN 120 AND 230  -- Filter out unrealistic heights\n",
    "ORDER BY subject_id, charttime\n",
    "\"\"\"\n",
    "\n",
    "# Step 2: Run the query to retrieve height data\n",
    "height_df = run_query(height_query)\n",
    "\n",
    "# Step 3: Calculate the average height per patient\n",
    "# Group by patient identifiers and calculate the mean height\n",
    "average_height_df = height_df.groupby(['subject_id', 'hadm_id']).agg(\n",
    "    average_height=('height', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "# Step 4: Merge the average height data with the main combined dataset\n",
    "combined_df_with_avg_height = pd.merge(\n",
    "    combined_df_with_ap.copy(),\n",
    "    average_height_df[['subject_id', 'hadm_id', 'average_height']],\n",
    "    on=['subject_id', 'hadm_id'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(combined_df_with_avg_height.head())\n",
    "print(f\"Number of rows with average height data: {combined_df_with_avg_height.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhuyu/anaconda3/envs/COMP90089/lib/python3.12/site-packages/google/cloud/bigquery/table.py:1727: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       subject_id   hadm_id           charttime  itemid  respiratory_rate\n",
      "0        10004606  29242151 2159-02-20 18:19:00  220210              15.0\n",
      "20       10011668  22181970 2131-06-14 17:17:00  220210              19.0\n",
      "44       10015860  25085565 2186-09-15 18:00:00  220210              20.0\n",
      "61       10017531  22580355 2159-09-22 19:35:00  220210              26.0\n",
      "87       10049833  20762302 2168-05-24 16:44:00  220210              16.0\n",
      "...           ...       ...                 ...     ...               ...\n",
      "19991    19929625  29789943 2153-06-19 21:59:00  220210              18.0\n",
      "20039    19934880  20689670 2166-11-23 11:39:00  220210              15.0\n",
      "20062    19962418  25331514 2132-10-24 21:40:00  220210              16.0\n",
      "20087    19970491  22119205 2131-02-11 01:43:00  220210              15.0\n",
      "20108    19970491  25338284 2129-05-17 17:55:00  220210              23.0\n",
      "\n",
      "[825 rows x 5 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhuyu/anaconda3/envs/COMP90089/lib/python3.12/site-packages/google/cloud/bigquery/table.py:1727: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       subject_id   hadm_id           charttime  itemid  heart_rate\n",
      "0        10004606  29242151 2159-02-20 18:19:00  220045       107.0\n",
      "20       10011668  22181970 2131-06-14 17:17:00  220045       107.0\n",
      "44       10015860  25085565 2186-09-15 18:00:00  220045       114.0\n",
      "61       10017531  22580355 2159-09-22 19:35:00  220045       116.0\n",
      "87       10049833  20762302 2168-05-24 16:44:00  220045       124.0\n",
      "...           ...       ...                 ...     ...         ...\n",
      "20255    19929625  29789943 2153-06-19 21:58:00  220045       112.0\n",
      "20303    19934880  20689670 2166-11-23 11:39:00  220045        84.0\n",
      "20326    19962418  25331514 2132-10-24 21:40:00  220045       109.0\n",
      "20351    19970491  22119205 2131-02-11 01:42:00  220045       116.0\n",
      "20372    19970491  25338284 2129-05-17 17:55:00  220045        69.0\n",
      "\n",
      "[826 rows x 5 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhuyu/anaconda3/envs/COMP90089/lib/python3.12/site-packages/google/cloud/bigquery/table.py:1727: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     subject_id   hadm_id           charttime  itemid  oxygen_saturation\n",
      "0      10017531  22580355 2159-09-23 10:45:00   50817               95.0\n",
      "1      10057482  25416257 2145-03-23 21:08:00   50817               66.0\n",
      "11     10153439  22115349 2121-03-11 22:58:00   50817               94.0\n",
      "14     10163709  29550274 2148-03-23 03:39:00   50817               96.0\n",
      "16     10199560  24622638 2175-01-11 07:29:00   50817               44.0\n",
      "..          ...       ...                 ...     ...                ...\n",
      "635    19811045  27885031 2162-07-08 04:35:00   50817               79.0\n",
      "637    19859524  27439975 2151-01-30 21:35:00   50817               50.0\n",
      "638    19882958  29628147 2182-08-29 18:52:00   50817               80.0\n",
      "639    19904101  23626019 2131-04-22 23:52:00   50817               97.0\n",
      "640    19962418  25331514 2132-10-25 01:30:00   50817               69.0\n",
      "\n",
      "[260 rows x 5 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhuyu/anaconda3/envs/COMP90089/lib/python3.12/site-packages/google/cloud/bigquery/table.py:1727: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     subject_id   hadm_id           charttime  itemid  temperature\n",
      "0      10064759  25061074 2173-03-22 19:50:00   50825         37.5\n",
      "1      10153439  22115349 2121-03-11 22:58:00   50825         40.4\n",
      "3      10157331  26293454 2175-05-31 10:19:00   50825         37.0\n",
      "7      10163709  29550274 2148-03-22 23:16:00   50825         36.5\n",
      "9      10199560  24622638 2175-01-11 02:09:00   50825         33.6\n",
      "..          ...       ...                 ...     ...          ...\n",
      "559    19734308  27089714 2166-02-28 03:45:00   50825         37.1\n",
      "560    19776126  20550940 2184-03-19 22:42:00   50825         36.5\n",
      "562    19811045  27885031 2162-07-07 22:50:00   50825         37.8\n",
      "567    19873806  23963601 2156-10-07 06:08:00   50825         37.2\n",
      "568    19962418  25331514 2132-10-24 21:46:00   50825         36.1\n",
      "\n",
      "[253 rows x 5 columns]\n",
      "   subject_id   hadm_id    charttime_lipase  lipase_level           admittime  \\\n",
      "0    10002976  27179825                 NaT           NaN 2145-02-28 19:44:00   \n",
      "1    10003400  23559586                 NaT           NaN 2137-08-04 00:07:00   \n",
      "2    10004606  29242151 2159-02-20 18:30:00        1222.0 2159-02-20 13:43:00   \n",
      "3    10006431  24638489 2129-01-23 23:36:00         508.0 2129-01-24 01:08:00   \n",
      "4    10006513  29846618                 NaT           NaN 2127-03-27 14:52:00   \n",
      "\n",
      "            dischtime gender  approximate_age_at_admission  \\\n",
      "0 2145-03-05 16:45:00      M                            70   \n",
      "1 2137-09-02 17:05:00      F                            72   \n",
      "2 2159-03-06 16:51:00      F                            64   \n",
      "3 2129-01-30 16:50:00      F                            66   \n",
      "4 2127-03-28 15:20:00      M                            42   \n",
      "\n",
      "                     race  actual_age  ...           charttime  crp_level  \\\n",
      "0                   WHITE          71  ... 2145-03-01 07:30:00      243.8   \n",
      "1  BLACK/AFRICAN AMERICAN          75  ... 2137-08-05 04:38:00      156.2   \n",
      "2                   WHITE          64  ...                 NaT        NaN   \n",
      "3                   WHITE          67  ...                 NaT        NaN   \n",
      "4                   OTHER          51  ... 2127-03-26 21:15:00      253.0   \n",
      "\n",
      "  icd_code  is_confirmed_ap average_weight  charlson_comorbidity_index  \\\n",
      "0      NaN            False            NaN                           5   \n",
      "1      NaN            False     104.366667                           5   \n",
      "2    K8510             True      56.300000                           4   \n",
      "3    K8580             True            NaN                           3   \n",
      "4      NaN            False            NaN                           2   \n",
      "\n",
      "  respiratory_rate  heart_rate  oxygen_saturation  temperature  \n",
      "0              NaN         NaN                NaN          NaN  \n",
      "1              NaN         NaN                NaN          NaN  \n",
      "2             15.0       107.0                NaN          NaN  \n",
      "3              NaN         NaN                NaN          NaN  \n",
      "4              NaN         NaN                NaN          NaN  \n",
      "\n",
      "[5 rows x 24 columns]\n",
      "Number of rows in the combined dataset with vital signs: 3722\n"
     ]
    }
   ],
   "source": [
    "# # 8. Get vital signs info\n",
    "# # Step 1: Get the list of unique subject_id and hadm_id\n",
    "# subject_ids = combined_df_with_ap['subject_id'].dropna().unique().tolist()\n",
    "# hadm_ids = combined_df_with_ap['hadm_id'].dropna().unique().tolist()\n",
    "\n",
    "# # Step 2: Define the time limit for the first 24 hours\n",
    "# time_limit = 24 * 60 * 60  # 24 hours in seconds\n",
    "\n",
    "# # Step 3: Modify each query to select only the first record within 24 hours of admission\n",
    "\n",
    "# # 1.1 Respiratory Rate (RR)\n",
    "# icu_respiratory_rate_query = f\"\"\"\n",
    "# SELECT icu.subject_id, icu.hadm_id, icu.charttime, icu.itemid, icu.valuenum AS respiratory_rate,\n",
    "# FROM `physionet-data.mimiciv_icu.chartevents` icu\n",
    "# JOIN `physionet-data.mimiciv_hosp.admissions` adm\n",
    "# ON icu.subject_id = adm.subject_id AND icu.hadm_id = adm.hadm_id\n",
    "# WHERE icu.itemid = 220210\n",
    "# AND TIMESTAMP_DIFF(icu.charttime, adm.admittime, SECOND) <= {time_limit}\n",
    "# AND icu.subject_id IN ({', '.join(map(str, subject_ids))})\n",
    "# AND icu.hadm_id IN ({', '.join(map(str, hadm_ids))})\n",
    "# ORDER BY icu.subject_id, icu.hadm_id, icu.charttime\n",
    "# \"\"\"\n",
    "# icu_respiratory_rate_df = run_query(icu_respiratory_rate_query)\n",
    "# icu_respiratory_rate_df = icu_respiratory_rate_df.drop_duplicates(subset=['subject_id', 'hadm_id'], keep='first')\n",
    "# print(icu_respiratory_rate_df)\n",
    "\n",
    "# # 1.2 Heart Rate (HR)\n",
    "# icu_heart_rate_query = f\"\"\"\n",
    "# SELECT icu.subject_id, icu.hadm_id, icu.charttime, icu.itemid, icu.valuenum AS heart_rate\n",
    "# FROM `physionet-data.mimiciv_icu.chartevents` icu\n",
    "# JOIN `physionet-data.mimiciv_hosp.admissions` adm\n",
    "# ON icu.subject_id = adm.subject_id AND icu.hadm_id = adm.hadm_id\n",
    "# WHERE icu.itemid = 220045\n",
    "# AND TIMESTAMP_DIFF(icu.charttime, adm.admittime, SECOND) <= {time_limit}\n",
    "# AND icu.subject_id IN ({', '.join(map(str, subject_ids))})\n",
    "# AND icu.hadm_id IN ({', '.join(map(str, hadm_ids))})\n",
    "# ORDER BY icu.subject_id, icu.hadm_id, icu.charttime\n",
    "# \"\"\"\n",
    "# icu_heart_rate_df = run_query(icu_heart_rate_query)\n",
    "# icu_heart_rate_df = icu_heart_rate_df.drop_duplicates(subset=['subject_id', 'hadm_id'], keep='first')\n",
    "# print(icu_heart_rate_df)\n",
    "\n",
    "# # 1.3 Oxygen Saturation (OS)\n",
    "# hosp_oxygen_saturation_query = f\"\"\"\n",
    "# SELECT hosp.subject_id, hosp.hadm_id, hosp.charttime, hosp.itemid, hosp.valuenum AS oxygen_saturation\n",
    "# FROM `physionet-data.mimiciv_hosp.labevents` hosp\n",
    "# JOIN `physionet-data.mimiciv_hosp.admissions` adm\n",
    "# ON hosp.subject_id = adm.subject_id AND hosp.hadm_id = adm.hadm_id\n",
    "# WHERE hosp.itemid = 50817\n",
    "# AND TIMESTAMP_DIFF(hosp.charttime, adm.admittime, SECOND) <= {time_limit}\n",
    "# AND hosp.subject_id IN ({', '.join(map(str, subject_ids))})\n",
    "# AND hosp.hadm_id IN ({', '.join(map(str, hadm_ids))})\n",
    "# ORDER BY hosp.subject_id, hosp.hadm_id, hosp.charttime\n",
    "# \"\"\"\n",
    "# hosp_oxygen_saturation_df = run_query(hosp_oxygen_saturation_query)\n",
    "# hosp_oxygen_saturation_df = hosp_oxygen_saturation_df.drop_duplicates(subset=['subject_id', 'hadm_id'], keep='first')\n",
    "# print(hosp_oxygen_saturation_df)\n",
    "\n",
    "# # 1.4 Temperature\n",
    "# hosp_temperature_query = f\"\"\"\n",
    "# SELECT hosp.subject_id, hosp.hadm_id, hosp.charttime, hosp.itemid, hosp.valuenum AS temperature\n",
    "# FROM `physionet-data.mimiciv_hosp.labevents` hosp\n",
    "# JOIN `physionet-data.mimiciv_hosp.admissions` adm\n",
    "# ON hosp.subject_id = adm.subject_id AND hosp.hadm_id = adm.hadm_id\n",
    "# WHERE hosp.itemid = 50825\n",
    "# AND TIMESTAMP_DIFF(hosp.charttime, adm.admittime, SECOND) <= {time_limit}\n",
    "# AND hosp.subject_id IN ({', '.join(map(str, subject_ids))})\n",
    "# AND hosp.hadm_id IN ({', '.join(map(str, hadm_ids))})\n",
    "# ORDER BY hosp.subject_id, hosp.hadm_id, hosp.charttime\n",
    "# \"\"\"\n",
    "# hosp_temperature_df = run_query(hosp_temperature_query)\n",
    "# hosp_temperature_df = hosp_temperature_df.drop_duplicates(subset=['subject_id', 'hadm_id'], keep='first')\n",
    "# print(hosp_temperature_df)\n",
    "\n",
    "# # Step 4: Merge these results with the main dataset\n",
    "# combined_df_with_vitals = combined_df_with_ap.copy()\n",
    "# combined_df_with_vitals = pd.merge(combined_df_with_vitals, icu_respiratory_rate_df[['subject_id', 'hadm_id', 'respiratory_rate']], on=['subject_id', 'hadm_id'], how='left')\n",
    "# combined_df_with_vitals = pd.merge(combined_df_with_vitals, icu_heart_rate_df[['subject_id', 'hadm_id', 'heart_rate']], on=['subject_id', 'hadm_id'], how='left')\n",
    "# combined_df_with_vitals = pd.merge(combined_df_with_vitals, hosp_oxygen_saturation_df[['subject_id', 'hadm_id', 'oxygen_saturation']], on=['subject_id', 'hadm_id'], how='left')\n",
    "# combined_df_with_vitals = pd.merge(combined_df_with_vitals, hosp_temperature_df[['subject_id', 'hadm_id', 'temperature']], on=['subject_id', 'hadm_id'], how='left')\n",
    "\n",
    "# # Display the final combined dataset\n",
    "# print(combined_df_with_vitals.head())\n",
    "# print(f\"Number of rows in the combined dataset with vital signs: {combined_df_with_vitals.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhuyu/anaconda3/envs/COMP90089/lib/python3.12/site-packages/google/cloud/bigquery/table.py:1727: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   subject_id   hadm_id           charttime  lipase_level           admittime  \\\n",
      "0    10002976  27179825                 NaT           NaN 2145-02-28 19:44:00   \n",
      "1    10003400  23559586                 NaT           NaN 2137-08-04 00:07:00   \n",
      "2    10004606  29242151 2159-02-20 18:30:00        1222.0 2159-02-20 13:43:00   \n",
      "3    10006431  24638489 2129-01-23 23:36:00         508.0 2129-01-24 01:08:00   \n",
      "4    10006513  29846618                 NaT           NaN 2127-03-27 14:52:00   \n",
      "\n",
      "            dischtime gender  approximate_age_at_admission  \\\n",
      "0 2145-03-05 16:45:00      M                            70   \n",
      "1 2137-09-02 17:05:00      F                            72   \n",
      "2 2159-03-06 16:51:00      F                            64   \n",
      "3 2129-01-30 16:50:00      F                            66   \n",
      "4 2127-03-28 15:20:00      M                            42   \n",
      "\n",
      "                     race  actual_age  ...  charlson_comorbidity_index  \\\n",
      "0                   WHITE          71  ...                           5   \n",
      "1  BLACK/AFRICAN AMERICAN          75  ...                           5   \n",
      "2                   WHITE          64  ...                           4   \n",
      "3                   WHITE          67  ...                           3   \n",
      "4                   OTHER          51  ...                           2   \n",
      "\n",
      "   average_height  first_charttime_vital  heart_rate_vital   sbp_vital  \\\n",
      "0             NaN                    NaT               NaN         NaN   \n",
      "1           165.0    2137-08-10 19:00:00        103.488323   96.430380   \n",
      "2           163.0    2159-02-20 18:00:00         82.614754  154.286822   \n",
      "3             NaN                    NaT               NaN         NaN   \n",
      "4             NaN                    NaT               NaN         NaN   \n",
      "\n",
      "   dbp_vital  mbp_vital  resp_rate_vital  temperature_c_vital spo2_vital  \n",
      "0        NaN        NaN              NaN                  NaN        NaN  \n",
      "1  57.356540  66.955696        19.505030                36.42  98.287671  \n",
      "2  60.093023  86.558140        15.574627                37.32  95.860656  \n",
      "3        NaN        NaN              NaN                  NaN        NaN  \n",
      "4        NaN        NaN              NaN                  NaN        NaN  \n",
      "\n",
      "[5 rows x 27 columns]\n",
      "Number of rows in the combined dataset with vital signs: 4357\n"
     ]
    }
   ],
   "source": [
    "# 8. Get vital signs info with '_vital' prefix\n",
    "# Step 1: Retrieve the list of unique subject_id and hadm_id\n",
    "subject_ids = combined_df_with_ap['subject_id'].dropna().unique().tolist()\n",
    "hadm_ids = combined_df_with_ap['hadm_id'].dropna().unique().tolist()\n",
    "\n",
    "\n",
    "# Step 3: Modify the query to retrieve the first vital sign record within 24 hours of admission\n",
    "vital_signs_query = f\"\"\"\n",
    "SELECT \n",
    "    ce.subject_id,\n",
    "    ce.hadm_id,\n",
    "    MIN(ce.charttime) AS first_charttime_vital,\n",
    "    \n",
    "    -- Average heart rate within the first record in 24 hours\n",
    "    AVG(CASE WHEN itemid = 220045 AND valuenum > 0 AND valuenum < 300 THEN valuenum ELSE NULL END) AS heart_rate_vital,\n",
    "    \n",
    "    -- Average systolic blood pressure (non-invasive and arterial combined)\n",
    "    AVG(CASE WHEN itemid IN (220179, 220050) AND valuenum > 0 AND valuenum < 400 THEN valuenum ELSE NULL END) AS sbp_vital,\n",
    "    \n",
    "    -- Average diastolic blood pressure (non-invasive and arterial combined)\n",
    "    AVG(CASE WHEN itemid IN (220180, 220051) AND valuenum > 0 AND valuenum < 300 THEN valuenum ELSE NULL END) AS dbp_vital,\n",
    "    \n",
    "    -- Mean arterial pressure (non-invasive and arterial combined)\n",
    "    AVG(CASE WHEN itemid IN (220052, 220181, 225312) AND valuenum > 0 AND valuenum < 300 THEN valuenum ELSE NULL END) AS mbp_vital,\n",
    "    \n",
    "    -- Average respiratory rate\n",
    "    AVG(CASE WHEN itemid IN (220210, 224690) AND valuenum > 0 AND valuenum < 70 THEN valuenum ELSE NULL END) AS resp_rate_vital,\n",
    "    \n",
    "    -- Temperature in Celsius\n",
    "    ROUND(\n",
    "        AVG(\n",
    "            CASE \n",
    "                WHEN itemid = 223761 AND valuenum > 70 AND valuenum < 120 THEN (valuenum - 32) / 1.8 -- Convert Fahrenheit to Celsius\n",
    "                WHEN itemid = 223762 AND valuenum > 10 AND valuenum < 50 THEN valuenum\n",
    "                ELSE NULL \n",
    "            END\n",
    "        ), 2) AS temperature_c_vital,\n",
    "    \n",
    "    -- Average oxygen saturation (SpO2)\n",
    "    AVG(CASE WHEN itemid = 220277 AND valuenum > 0 AND valuenum <= 100 THEN valuenum ELSE NULL END) AS spo2_vital\n",
    "FROM `physionet-data.mimiciv_icu.chartevents` AS ce\n",
    "JOIN `physionet-data.mimiciv_hosp.admissions` AS adm\n",
    "ON ce.subject_id = adm.subject_id AND ce.hadm_id = adm.hadm_id\n",
    "WHERE ce.hadm_id IS NOT NULL\n",
    "AND ce.itemid IN (\n",
    "    220045,   -- Heart Rate\n",
    "    220179,   -- Non-Invasive Blood Pressure Systolic\n",
    "    220180,   -- Non-Invasive Blood Pressure Diastolic\n",
    "    220181,   -- Non-Invasive Blood Pressure Mean\n",
    "    220210,   -- Respiratory Rate\n",
    "    220050,   -- Arterial Blood Pressure Systolic\n",
    "    220051,   -- Arterial Blood Pressure Diastolic\n",
    "    220052,   -- Arterial Blood Pressure Mean\n",
    "    224690,   -- Respiratory Rate (Total)\n",
    "    220277,   -- SpO2, peripheral\n",
    "    223762,   -- Temperature in Celsius\n",
    "    223761    -- Temperature in Fahrenheit\n",
    ")\n",
    "AND ce.subject_id IN ({', '.join(map(str, subject_ids))})\n",
    "AND ce.hadm_id IN ({', '.join(map(str, hadm_ids))})\n",
    "GROUP BY ce.subject_id, ce.hadm_id\n",
    "ORDER BY ce.subject_id, ce.hadm_id, first_charttime_vital\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query\n",
    "vital_signs_df = run_query(vital_signs_query)\n",
    "\n",
    "# Merge the vital signs data with the main dataset and add '_vital' prefix\n",
    "combined_df_with_vitals = pd.merge(\n",
    "    combined_df_with_avg_height.copy(),\n",
    "    vital_signs_df,\n",
    "    on=['subject_id', 'hadm_id'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Display sample of the combined dataset\n",
    "print(combined_df_with_vitals.head())\n",
    "print(f\"Number of rows in the combined dataset with vital signs: {combined_df_with_vitals.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhuyu/anaconda3/envs/COMP90089/lib/python3.12/site-packages/google/cloud/bigquery/table.py:1727: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   subject_id   hadm_id           charttime  lipase_level           admittime  \\\n",
      "0    10002976  27179825                 NaT           NaN 2145-02-28 19:44:00   \n",
      "1    10003400  23559586                 NaT           NaN 2137-08-04 00:07:00   \n",
      "2    10004606  29242151 2159-02-20 18:30:00        1222.0 2159-02-20 13:43:00   \n",
      "3    10006431  24638489 2129-01-23 23:36:00         508.0 2129-01-24 01:08:00   \n",
      "4    10006513  29846618                 NaT           NaN 2127-03-27 14:52:00   \n",
      "\n",
      "            dischtime gender  approximate_age_at_admission  \\\n",
      "0 2145-03-05 16:45:00      M                            70   \n",
      "1 2137-09-02 17:05:00      F                            72   \n",
      "2 2159-03-06 16:51:00      F                            64   \n",
      "3 2129-01-30 16:50:00      F                            66   \n",
      "4 2127-03-28 15:20:00      M                            42   \n",
      "\n",
      "                     race  actual_age  ...  total_protein_chemistry  \\\n",
      "0                   WHITE          71  ...                      NaN   \n",
      "1  BLACK/AFRICAN AMERICAN          75  ...                      5.6   \n",
      "2                   WHITE          64  ...                      NaN   \n",
      "3                   WHITE          67  ...                      NaN   \n",
      "4                   OTHER          51  ...                      NaN   \n",
      "\n",
      "   aniongap_chemistry  bicarbonate_chemistry  bun_chemistry calcium_chemistry  \\\n",
      "0                19.0                   28.0           34.0               8.6   \n",
      "1                23.0                   30.0           41.0               8.8   \n",
      "2                20.0                   28.0           11.0               9.6   \n",
      "3                17.0                   27.0            9.0               9.6   \n",
      "4                17.0                   23.0           32.0               9.7   \n",
      "\n",
      "   chloride_chemistry  creatinine_chemistry  glucose_chemistry  \\\n",
      "0               103.0                   1.6              378.0   \n",
      "1               111.0                   2.3              159.0   \n",
      "2               110.0                   0.9              144.0   \n",
      "3                98.0                   0.5              102.0   \n",
      "4               103.0                   1.8              165.0   \n",
      "\n",
      "   sodium_chemistry potassium_chemistry  \n",
      "0             141.0                 4.8  \n",
      "1             142.0                 6.0  \n",
      "2             143.0                 4.5  \n",
      "3             139.0                 4.6  \n",
      "4             141.0                 5.0  \n",
      "\n",
      "[5 rows x 40 columns]\n",
      "Number of rows in the combined dataset with chemistry info: 4357\n"
     ]
    }
   ],
   "source": [
    "# 9. Get chemistries info\n",
    "chemistry_query = f\"\"\"\n",
    "-- Extract chemistry labs for the first measurement after admission\n",
    "SELECT \n",
    "    le.subject_id,\n",
    "    le.hadm_id,\n",
    "    MIN(le.charttime) AS first_charttime_chemistry,  -- Record the earliest chart time for each patient\n",
    "    -- Chemistry measurements with thresholds to exclude outliers\n",
    "    MAX(CASE WHEN itemid = 50862 AND valuenum <= 10 THEN valuenum ELSE NULL END) AS albumin_chemistry,\n",
    "    MAX(CASE WHEN itemid = 50930 AND valuenum <= 10 THEN valuenum ELSE NULL END) AS globulin_chemistry,\n",
    "    MAX(CASE WHEN itemid = 50976 AND valuenum <= 20 THEN valuenum ELSE NULL END) AS total_protein_chemistry,\n",
    "    MAX(CASE WHEN itemid = 50868 AND valuenum <= 10000 THEN valuenum ELSE NULL END) AS aniongap_chemistry,\n",
    "    MAX(CASE WHEN itemid = 50882 AND valuenum <= 10000 THEN valuenum ELSE NULL END) AS bicarbonate_chemistry,\n",
    "    MAX(CASE WHEN itemid = 51006 AND valuenum <= 300 THEN valuenum ELSE NULL END) AS bun_chemistry,\n",
    "    MAX(CASE WHEN itemid = 50893 AND valuenum <= 10000 THEN valuenum ELSE NULL END) AS calcium_chemistry,\n",
    "    MAX(CASE WHEN itemid = 50902 AND valuenum <= 10000 THEN valuenum ELSE NULL END) AS chloride_chemistry,\n",
    "    MAX(CASE WHEN itemid = 50912 AND valuenum <= 150 THEN valuenum ELSE NULL END) AS creatinine_chemistry,\n",
    "    MAX(CASE WHEN itemid = 50931 AND valuenum <= 10000 THEN valuenum ELSE NULL END) AS glucose_chemistry,\n",
    "    MAX(CASE WHEN itemid = 50983 AND valuenum <= 200 THEN valuenum ELSE NULL END) AS sodium_chemistry,\n",
    "    MAX(CASE WHEN itemid = 50971 AND valuenum <= 30 THEN valuenum ELSE NULL END) AS potassium_chemistry\n",
    "FROM `physionet-data.mimiciv_hosp.labevents` AS le\n",
    "JOIN `physionet-data.mimiciv_hosp.admissions` AS adm\n",
    "ON le.subject_id = adm.subject_id AND le.hadm_id = adm.hadm_id\n",
    "WHERE le.hadm_id IS NOT NULL\n",
    "AND le.itemid IN (\n",
    "    50862, -- Albumin\n",
    "    50930, -- Globulin\n",
    "    50976, -- Total Protein\n",
    "    50868, -- Anion Gap\n",
    "    50882, -- Bicarbonate\n",
    "    50893, -- Calcium\n",
    "    50912, -- Creatinine\n",
    "    50902, -- Chloride\n",
    "    50931, -- Glucose\n",
    "    50971, -- Potassium\n",
    "    50983, -- Sodium\n",
    "    51006  -- Urea Nitrogen (BUN)\n",
    ")\n",
    "AND le.subject_id IN ({', '.join(map(str, subject_ids))})\n",
    "AND le.hadm_id IN ({', '.join(map(str, hadm_ids))})\n",
    "GROUP BY le.subject_id, le.hadm_id\n",
    "ORDER BY le.subject_id, le.hadm_id, first_charttime_chemistry\n",
    "\"\"\"\n",
    "\n",
    "# Execute the chemistry query\n",
    "chemistry_df = run_query(chemistry_query)\n",
    "\n",
    "# Merge the chemistry data with the main dataset containing vital signs and patient info\n",
    "combined_df_with_chemistry = pd.merge(\n",
    "    combined_df_with_vitals.copy(),\n",
    "    chemistry_df,\n",
    "    on=['subject_id', 'hadm_id'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Display sample of the combined dataset\n",
    "print(combined_df_with_chemistry.head())\n",
    "print(f\"Number of rows in the combined dataset with chemistry info: {combined_df_with_chemistry.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhuyu/anaconda3/envs/COMP90089/lib/python3.12/site-packages/google/cloud/bigquery/table.py:1727: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   subject_id   hadm_id           charttime  lipase_level           admittime  \\\n",
      "0    10002976  27179825                 NaT           NaN 2145-02-28 19:44:00   \n",
      "1    10003400  23559586                 NaT           NaN 2137-08-04 00:07:00   \n",
      "2    10004606  29242151 2159-02-20 18:30:00        1222.0 2159-02-20 13:43:00   \n",
      "3    10006431  24638489 2129-01-23 23:36:00         508.0 2129-01-24 01:08:00   \n",
      "4    10006513  29846618                 NaT           NaN 2127-03-27 14:52:00   \n",
      "\n",
      "            dischtime gender  approximate_age_at_admission  \\\n",
      "0 2145-03-05 16:45:00      M                            70   \n",
      "1 2137-09-02 17:05:00      F                            72   \n",
      "2 2159-03-06 16:51:00      F                            64   \n",
      "3 2129-01-30 16:50:00      F                            66   \n",
      "4 2127-03-28 15:20:00      M                            42   \n",
      "\n",
      "                     race  actual_age  ...  alp_enzyme  ast_enzyme  \\\n",
      "0                   WHITE          71  ...         NaN         NaN   \n",
      "1  BLACK/AFRICAN AMERICAN          75  ...       189.0        34.0   \n",
      "2                   WHITE          64  ...       252.0       333.0   \n",
      "3                   WHITE          67  ...       138.0        14.0   \n",
      "4                   OTHER          51  ...         NaN         NaN   \n",
      "\n",
      "   amylase_enzyme  bilirubin_total_enzyme bilirubin_direct_enzyme  \\\n",
      "0             NaN                     NaN                     NaN   \n",
      "1             NaN                     1.2                     0.2   \n",
      "2           302.0                     1.7                     NaN   \n",
      "3           177.0                     0.6                     NaN   \n",
      "4             NaN                     NaN                     NaN   \n",
      "\n",
      "   bilirubin_indirect_enzyme  ck_cpk_enzyme  ck_mb_enzyme  ggt_enzyme  \\\n",
      "0                        NaN          222.0           NaN         NaN   \n",
      "1                        0.2            NaN           NaN         NaN   \n",
      "2                        NaN            NaN           NaN         NaN   \n",
      "3                        NaN            NaN           NaN         NaN   \n",
      "4                        NaN            NaN           NaN         NaN   \n",
      "\n",
      "  ld_ldh_enzyme  \n",
      "0           NaN  \n",
      "1         264.0  \n",
      "2           NaN  \n",
      "3         135.0  \n",
      "4           NaN  \n",
      "\n",
      "[5 rows x 52 columns]\n",
      "Number of rows in the combined dataset with enzyme info: 4357\n"
     ]
    }
   ],
   "source": [
    "# 10. Get enzymes info\n",
    "enzyme_query = f\"\"\"\n",
    "-- Extract enzyme labs for the first measurement after admission\n",
    "SELECT \n",
    "    le.subject_id,\n",
    "    le.hadm_id,\n",
    "    MIN(le.charttime) AS first_charttime_enzyme,  -- Record the earliest chart time for each patient\n",
    "    -- Enzyme measurements with thresholds to exclude outliers\n",
    "    MAX(CASE WHEN itemid = 50861 AND valuenum > 0 THEN valuenum ELSE NULL END) AS alt_enzyme,\n",
    "    MAX(CASE WHEN itemid = 50863 AND valuenum > 0 THEN valuenum ELSE NULL END) AS alp_enzyme,\n",
    "    MAX(CASE WHEN itemid = 50878 AND valuenum > 0 THEN valuenum ELSE NULL END) AS ast_enzyme,\n",
    "    MAX(CASE WHEN itemid = 50867 AND valuenum > 0 THEN valuenum ELSE NULL END) AS amylase_enzyme,\n",
    "    MAX(CASE WHEN itemid = 50885 AND valuenum > 0 THEN valuenum ELSE NULL END) AS bilirubin_total_enzyme,\n",
    "    MAX(CASE WHEN itemid = 50883 AND valuenum > 0 THEN valuenum ELSE NULL END) AS bilirubin_direct_enzyme,\n",
    "    MAX(CASE WHEN itemid = 50884 AND valuenum > 0 THEN valuenum ELSE NULL END) AS bilirubin_indirect_enzyme,\n",
    "    MAX(CASE WHEN itemid = 50910 AND valuenum > 0 THEN valuenum ELSE NULL END) AS ck_cpk_enzyme,\n",
    "    MAX(CASE WHEN itemid = 50911 AND valuenum > 0 THEN valuenum ELSE NULL END) AS ck_mb_enzyme,\n",
    "    MAX(CASE WHEN itemid = 50927 AND valuenum > 0 THEN valuenum ELSE NULL END) AS ggt_enzyme,\n",
    "    MAX(CASE WHEN itemid = 50954 AND valuenum > 0 THEN valuenum ELSE NULL END) AS ld_ldh_enzyme\n",
    "FROM `physionet-data.mimiciv_hosp.labevents` AS le\n",
    "JOIN `physionet-data.mimiciv_hosp.admissions` AS adm\n",
    "ON le.subject_id = adm.subject_id AND le.hadm_id = adm.hadm_id\n",
    "WHERE le.hadm_id IS NOT NULL\n",
    "AND le.itemid IN (\n",
    "    50861, -- Alanine transaminase (ALT)\n",
    "    50863, -- Alkaline phosphatase (ALP)\n",
    "    50878, -- Aspartate transaminase (AST)\n",
    "    50867, -- Amylase\n",
    "    50885, -- Total Bilirubin\n",
    "    50884, -- Indirect Bilirubin\n",
    "    50883, -- Direct Bilirubin\n",
    "    50910, -- CK-CPK\n",
    "    50911, -- CK-MB\n",
    "    50927, -- Gamma Glutamyltransferase (GGT)\n",
    "    50954  -- LD-LDH\n",
    ")\n",
    "AND le.subject_id IN ({', '.join(map(str, subject_ids))})\n",
    "AND le.hadm_id IN ({', '.join(map(str, hadm_ids))})\n",
    "GROUP BY le.subject_id, le.hadm_id\n",
    "ORDER BY le.subject_id, le.hadm_id, first_charttime_enzyme\n",
    "\"\"\"\n",
    "\n",
    "# Execute the enzyme query\n",
    "enzyme_df = run_query(enzyme_query)\n",
    "\n",
    "# Merge the enzyme data with the main dataset containing chemistry, vital signs, and patient info\n",
    "combined_df_with_enzymes = pd.merge(\n",
    "    combined_df_with_chemistry.copy(),\n",
    "    enzyme_df,\n",
    "    on=['subject_id', 'hadm_id'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Display sample of the combined dataset\n",
    "print(combined_df_with_enzymes.head())\n",
    "print(f\"Number of rows in the combined dataset with enzyme info: {combined_df_with_enzymes.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns without NaN values:\n",
      "Index(['subject_id', 'is_confirmed_ap'], dtype='object')\n",
      "Columns with NaN values and their counts:\n",
      "hadm_id                           91\n",
      "charttime                       2058\n",
      "lipase_level                    2058\n",
      "admittime                         91\n",
      "dischtime                         91\n",
      "gender                            91\n",
      "approximate_age_at_admission      91\n",
      "race                              91\n",
      "actual_age                        91\n",
      "in_hospital_death                 91\n",
      "length_of_stay                    91\n",
      "amylase_level                   4025\n",
      "crp_level                       2410\n",
      "icd_code                        2851\n",
      "average_weight                  3021\n",
      "charlson_comorbidity_index        91\n",
      "average_height                  3502\n",
      "first_charttime_vital           3019\n",
      "heart_rate_vital                3019\n",
      "sbp_vital                       3021\n",
      "dbp_vital                       3022\n",
      "mbp_vital                       3022\n",
      "resp_rate_vital                 3020\n",
      "temperature_c_vital             3024\n",
      "spo2_vital                      3022\n",
      "first_charttime_chemistry        112\n",
      "albumin_chemistry               1576\n",
      "globulin_chemistry              4197\n",
      "total_protein_chemistry         4006\n",
      "aniongap_chemistry               116\n",
      "bicarbonate_chemistry            116\n",
      "bun_chemistry                    116\n",
      "calcium_chemistry                217\n",
      "chloride_chemistry               115\n",
      "creatinine_chemistry             113\n",
      "glucose_chemistry                115\n",
      "sodium_chemistry                 115\n",
      "potassium_chemistry              115\n",
      "first_charttime_enzyme           504\n",
      "alt_enzyme                       717\n",
      "alp_enzyme                       728\n",
      "ast_enzyme                       703\n",
      "amylase_enzyme                  2850\n",
      "bilirubin_total_enzyme           739\n",
      "bilirubin_direct_enzyme         3635\n",
      "bilirubin_indirect_enzyme       3629\n",
      "ck_cpk_enzyme                   2996\n",
      "ck_mb_enzyme                    3391\n",
      "ggt_enzyme                      4184\n",
      "ld_ldh_enzyme                   1943\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "nan_counts = combined_df_with_enzymes.isna().sum()\n",
    "# Columns without NaN values\n",
    "print(\"Columns without NaN values:\")\n",
    "print(combined_df_with_enzymes.columns[combined_df_with_enzymes.isna().sum() == 0])\n",
    "# Columns with NaN values and their counts\n",
    "nan_columns = nan_counts[nan_counts > 0]\n",
    "print(\"Columns with NaN values and their counts:\")\n",
    "print(nan_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing `hadm_id` in patient_info_df: 0\n",
      "Missing `hadm_id` in lipase_values_df: 155151\n",
      "Missing `hadm_id` in amylase_values_df: 40469\n",
      "Missing `hadm_id` in crp_values_df: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing `hadm_id` in patient_info_df:\", patient_info_df['hadm_id'].isna().sum())\n",
    "print(\"Missing `hadm_id` in lipase_values_df:\", lipase_values_df['hadm_id'].isna().sum())\n",
    "print(\"Missing `hadm_id` in amylase_values_df:\", amylase_values_df['hadm_id'].isna().sum())\n",
    "print(\"Missing `hadm_id` in crp_values_df:\", crp_values_df['hadm_id'].isna().sum())\n",
    "# Continue for all intermediate dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns without NaN values:\n",
      "Index(['subject_id', 'is_confirmed_ap'], dtype='object')\n",
      "Columns with NaN values and their counts:\n",
      "hadm_id                           91\n",
      "charttime                       2058\n",
      "lipase_level                    2058\n",
      "admittime                         91\n",
      "dischtime                         91\n",
      "gender                            91\n",
      "approximate_age_at_admission      91\n",
      "race                              91\n",
      "actual_age                        91\n",
      "in_hospital_death                 91\n",
      "length_of_stay                    91\n",
      "amylase_level                   4025\n",
      "crp_level                       2410\n",
      "icd_code                        2851\n",
      "average_weight                  3021\n",
      "charlson_comorbidity_index        91\n",
      "average_height                  3502\n",
      "first_charttime_vital           3019\n",
      "heart_rate_vital                3019\n",
      "sbp_vital                       3021\n",
      "dbp_vital                       3022\n",
      "mbp_vital                       3022\n",
      "resp_rate_vital                 3020\n",
      "temperature_c_vital             3024\n",
      "spo2_vital                      3022\n",
      "first_charttime_chemistry        112\n",
      "albumin_chemistry               1576\n",
      "globulin_chemistry              4197\n",
      "total_protein_chemistry         4006\n",
      "aniongap_chemistry               116\n",
      "bicarbonate_chemistry            116\n",
      "bun_chemistry                    116\n",
      "calcium_chemistry                217\n",
      "chloride_chemistry               115\n",
      "creatinine_chemistry             113\n",
      "glucose_chemistry                115\n",
      "sodium_chemistry                 115\n",
      "potassium_chemistry              115\n",
      "first_charttime_enzyme           504\n",
      "alt_enzyme                       717\n",
      "alp_enzyme                       728\n",
      "ast_enzyme                       703\n",
      "amylase_enzyme                  2850\n",
      "bilirubin_total_enzyme           739\n",
      "bilirubin_direct_enzyme         3635\n",
      "bilirubin_indirect_enzyme       3629\n",
      "ck_cpk_enzyme                   2996\n",
      "ck_mb_enzyme                    3391\n",
      "ggt_enzyme                      4184\n",
      "ld_ldh_enzyme                   1943\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Delete those rows with missing hadm_id\n",
    "combined_df_with_vitals = combined_df_with_enzymes.dropna(subset=['hadm_id'])\n",
    "\n",
    "nan_counts = combined_df_with_enzymes.isna().sum()\n",
    "# Columns without NaN values\n",
    "print(\"Columns without NaN values:\")\n",
    "print(combined_df_with_enzymes.columns[combined_df_with_enzymes.isna().sum() == 0])\n",
    "# Columns with NaN values and their counts\n",
    "nan_columns = nan_counts[nan_counts > 0]\n",
    "print(\"Columns with NaN values and their counts:\")\n",
    "print(nan_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a CSV file with the final combined dataset\n",
    "combined_df_with_vitals.to_csv('AP_ICD_CCI_dataset.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "COMP90089",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>charttime</th>\n",
       "      <th>lipase_level</th>\n",
       "      <th>admittime</th>\n",
       "      <th>dischtime</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>in_hospital_death</th>\n",
       "      <th>charttime_crp</th>\n",
       "      <th>crp_level</th>\n",
       "      <th>charttime_amylase</th>\n",
       "      <th>amylase_level</th>\n",
       "      <th>is_confirmed_ap</th>\n",
       "      <th>icd_code</th>\n",
       "      <th>seq_num</th>\n",
       "      <th>icd_version</th>\n",
       "      <th>severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10004606</td>\n",
       "      <td>29242151.0</td>\n",
       "      <td>2159-02-20 18:30:00</td>\n",
       "      <td>-0.044243</td>\n",
       "      <td>2159-02-20 13:43:00</td>\n",
       "      <td>2159-03-06 16:51:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.355612</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>166.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1327.0</td>\n",
       "      <td>True</td>\n",
       "      <td>G40409</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>severe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10004606</td>\n",
       "      <td>29242151.0</td>\n",
       "      <td>2159-02-20 18:30:00</td>\n",
       "      <td>-0.044243</td>\n",
       "      <td>2159-02-20 13:43:00</td>\n",
       "      <td>2159-03-06 16:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.355612</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>166.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1327.0</td>\n",
       "      <td>True</td>\n",
       "      <td>K8510</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>severe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10004606</td>\n",
       "      <td>29242151.0</td>\n",
       "      <td>2159-02-20 18:30:00</td>\n",
       "      <td>-0.044243</td>\n",
       "      <td>2159-02-20 13:43:00</td>\n",
       "      <td>2159-03-06 16:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.355612</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>166.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1327.0</td>\n",
       "      <td>True</td>\n",
       "      <td>G9340</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>severe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10004606</td>\n",
       "      <td>29242151.0</td>\n",
       "      <td>2159-02-20 18:30:00</td>\n",
       "      <td>-0.044243</td>\n",
       "      <td>2159-02-20 13:43:00</td>\n",
       "      <td>2159-03-06 16:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.355612</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>166.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1327.0</td>\n",
       "      <td>True</td>\n",
       "      <td>K8064</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>severe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10004606</td>\n",
       "      <td>29242151.0</td>\n",
       "      <td>2159-02-20 18:30:00</td>\n",
       "      <td>-0.044243</td>\n",
       "      <td>2159-02-20 13:43:00</td>\n",
       "      <td>2159-03-06 16:51:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.355612</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>166.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1327.0</td>\n",
       "      <td>True</td>\n",
       "      <td>E871</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>severe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id     hadm_id            charttime  lipase_level  \\\n",
       "0    10004606  29242151.0  2159-02-20 18:30:00     -0.044243   \n",
       "1    10004606  29242151.0  2159-02-20 18:30:00     -0.044243   \n",
       "2    10004606  29242151.0  2159-02-20 18:30:00     -0.044243   \n",
       "3    10004606  29242151.0  2159-02-20 18:30:00     -0.044243   \n",
       "4    10004606  29242151.0  2159-02-20 18:30:00     -0.044243   \n",
       "\n",
       "             admittime            dischtime  gender       age  \\\n",
       "0  2159-02-20 13:43:00  2159-03-06 16:51:00     1.0  0.355612   \n",
       "1  2159-02-20 13:43:00  2159-03-06 16:51:00     0.0  0.355612   \n",
       "2  2159-02-20 13:43:00  2159-03-06 16:51:00     0.0  0.355612   \n",
       "3  2159-02-20 13:43:00  2159-03-06 16:51:00     0.0  0.355612   \n",
       "4  2159-02-20 13:43:00  2159-03-06 16:51:00     1.0  0.355612   \n",
       "\n",
       "   in_hospital_death charttime_crp  crp_level charttime_amylase  \\\n",
       "0              False           NaN      166.0               NaN   \n",
       "1              False           NaN      166.0               NaN   \n",
       "2              False           NaN      166.0               NaN   \n",
       "3              False           NaN      166.0               NaN   \n",
       "4              False           NaN      166.0               NaN   \n",
       "\n",
       "   amylase_level  is_confirmed_ap icd_code  seq_num  icd_version severity  \n",
       "0         1327.0             True   G40409      1.0         10.0   severe  \n",
       "1         1327.0             True    K8510      2.0         10.0   severe  \n",
       "2         1327.0             True    G9340      3.0         10.0   severe  \n",
       "3         1327.0             True    K8064      4.0         10.0   severe  \n",
       "4         1327.0             True     E871      5.0         10.0   severe  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# load data\n",
    "df = pd.read_csv('AP_ICD_Lipase_CRP_Amylase_Dataset_Comorbid_Clean.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "in_hospital_death\n",
       "False    72511\n",
       "True     16405\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check unique value in subject_id\n",
    "df['subject_id'].nunique()\n",
    "\n",
    "# check in_hospital_death value\n",
    "df['in_hospital_death'].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   subject_id  lipase_level  crp_level  amylase_level       age  gender  \\\n",
      "0    10004606     -0.044243      166.0         1327.0  0.355612     1.0   \n",
      "1    10006431     -0.071294      166.0         1327.0  0.478369     1.0   \n",
      "2    10017531     -0.049983      185.1         1327.0  0.294233     1.0   \n",
      "3    10021357     -0.055003      166.0         1327.0  2.012836     1.0   \n",
      "4    10036086     -0.062997      166.0         1327.0 -0.074039     1.0   \n",
      "\n",
      "   severity  \n",
      "0    severe  \n",
      "1  moderate  \n",
      "2  critical  \n",
      "3    severe  \n",
      "4  critical  \n",
      "   lipase_level  gender       age  in_hospital_death  crp_level  \\\n",
      "0     -0.044243     1.0  0.355612              False      166.0   \n",
      "1     -0.044243     0.0  0.355612              False      166.0   \n",
      "2     -0.044243     0.0  0.355612              False      166.0   \n",
      "3     -0.044243     0.0  0.355612              False      166.0   \n",
      "4     -0.044243     1.0  0.355612              False      166.0   \n",
      "\n",
      "   amylase_level  is_confirmed_ap  seq_num  icd_version severity  \n",
      "0         1327.0             True      1.0         10.0   severe  \n",
      "1         1327.0             True      2.0         10.0   severe  \n",
      "2         1327.0             True      3.0         10.0   severe  \n",
      "3         1327.0             True      4.0         10.0   severe  \n",
      "4         1327.0             True      5.0         10.0   severe  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "# each subject_id has multiple rows, we need to aggregate the data\n",
    "df_clean_new = df.groupby('subject_id').agg({\n",
    "    'lipase_level': 'mean',\n",
    "    'crp_level': 'mean',\n",
    "    'amylase_level': 'mean',\n",
    "    'age': 'first',\n",
    "    'gender': 'first',\n",
    "    'severity': 'last',\n",
    "}).reset_index()\n",
    "\n",
    "print(df_clean_new.head())\n",
    "\n",
    "# Drop unnecessary columns (dates and IDs) for modeling purposes\n",
    "df_clean = df.drop(columns=['subject_id', 'hadm_id', 'charttime', 'admittime', 'dischtime', \n",
    "                            'charttime_crp', 'charttime_amylase', 'icd_code'])\n",
    "# df_clean = df_clean_new\n",
    "\n",
    "\n",
    "print(df_clean.head())\n",
    "# Encode 'severity' (target variable) as numerical\n",
    "label_encoder = LabelEncoder()\n",
    "df_clean['severity'] = label_encoder.fit_transform(df_clean['severity'])\n",
    "\n",
    "# Convert boolean columns to integers (0 and 1)\n",
    "bool_columns = df_clean.select_dtypes(include='bool').columns\n",
    "df_clean[bool_columns] = df_clean[bool_columns].astype(int)\n",
    "\n",
    "# Split dataset into features (X) and target (y)\n",
    "X = df_clean.drop(columns=['severity'])\n",
    "y = df_clean['severity']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize numerical features for better model performance\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7995389113810166,\n",
       " '              precision    recall  f1-score   support\\n\\n    critical       0.75      0.93      0.83      7908\\n       death       1.00      1.00      1.00      3219\\n        mild       1.00      0.38      0.55       196\\n    moderate       0.72      0.72      0.72      3968\\n      severe       0.96      0.28      0.44      2493\\n\\n    accuracy                           0.80     17784\\n   macro avg       0.89      0.66      0.71     17784\\nweighted avg       0.82      0.80      0.78     17784\\n',\n",
       " array([[7352,    0,    0,  553,    3],\n",
       "        [   0, 3219,    0,    0,    0],\n",
       "        [  76,    0,   74,   42,    4],\n",
       "        [1080,    0,    0, 2869,   19],\n",
       "        [1249,    0,    0,  539,  705]], dtype=int64))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = RandomForestClassifier(random_state=42, n_estimators=200, max_depth=15)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred, target_names=label_encoder.classes_)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "accuracy, report, conf_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nan\\anaconda3\\envs\\nansang\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [00:12:18] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.99\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      7908\n",
      "           1       1.00      1.00      1.00      3219\n",
      "           2       0.97      0.97      0.97       196\n",
      "           3       0.98      0.98      0.98      3968\n",
      "           4       0.97      0.97      0.97      2493\n",
      "\n",
      "    accuracy                           0.99     17784\n",
      "   macro avg       0.98      0.98      0.98     17784\n",
      "weighted avg       0.99      0.99      0.99     17784\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "model = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42, n_estimators=200, max_depth=15, learning_rate=0.1)\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    " \n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.71\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nan\\anaconda3\\envs\\nansang\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.84      0.70      7908\n",
      "           1       1.00      1.00      1.00      3219\n",
      "           2       0.00      0.00      0.00       196\n",
      "           3       0.45      0.38      0.41      3968\n",
      "           4       0.56      0.00      0.00      2493\n",
      "\n",
      "    accuracy                           0.64     17784\n",
      "   macro avg       0.52      0.45      0.42     17784\n",
      "weighted avg       0.62      0.64      0.58     17784\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nan\\anaconda3\\envs\\nansang\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Nan\\anaconda3\\envs\\nansang\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Nan\\anaconda3\\envs\\nansang\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lipase_level</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>in_hospital_death</th>\n",
       "      <th>crp_level</th>\n",
       "      <th>amylase_level</th>\n",
       "      <th>is_confirmed_ap</th>\n",
       "      <th>seq_num</th>\n",
       "      <th>icd_version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.044243</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.355612</td>\n",
       "      <td>0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>1327.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.044243</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.355612</td>\n",
       "      <td>0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>1327.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.044243</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.355612</td>\n",
       "      <td>0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>1327.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.044243</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.355612</td>\n",
       "      <td>0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>1327.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.044243</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.355612</td>\n",
       "      <td>0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>1327.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88911</th>\n",
       "      <td>-0.053033</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.503690</td>\n",
       "      <td>1</td>\n",
       "      <td>166.0</td>\n",
       "      <td>1327.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88912</th>\n",
       "      <td>-0.053033</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.503690</td>\n",
       "      <td>1</td>\n",
       "      <td>166.0</td>\n",
       "      <td>1327.0</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88913</th>\n",
       "      <td>-0.053033</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.503690</td>\n",
       "      <td>1</td>\n",
       "      <td>166.0</td>\n",
       "      <td>1327.0</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88914</th>\n",
       "      <td>-0.053033</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.503690</td>\n",
       "      <td>1</td>\n",
       "      <td>166.0</td>\n",
       "      <td>1327.0</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88915</th>\n",
       "      <td>-0.053033</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.503690</td>\n",
       "      <td>1</td>\n",
       "      <td>166.0</td>\n",
       "      <td>1327.0</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88916 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       lipase_level gender       age in_hospital_death  crp_level  \\\n",
       "0         -0.044243    1.0  0.355612                 0      166.0   \n",
       "1         -0.044243    0.0  0.355612                 0      166.0   \n",
       "2         -0.044243    0.0  0.355612                 0      166.0   \n",
       "3         -0.044243    0.0  0.355612                 0      166.0   \n",
       "4         -0.044243    1.0  0.355612                 0      166.0   \n",
       "...             ...    ...       ...               ...        ...   \n",
       "88911     -0.053033    1.0 -0.503690                 1      166.0   \n",
       "88912     -0.053033    1.0 -0.503690                 1      166.0   \n",
       "88913     -0.053033    1.0 -0.503690                 1      166.0   \n",
       "88914     -0.053033    0.0 -0.503690                 1      166.0   \n",
       "88915     -0.053033    1.0 -0.503690                 1      166.0   \n",
       "\n",
       "       amylase_level is_confirmed_ap  seq_num  icd_version  \n",
       "0             1327.0               1      1.0         10.0  \n",
       "1             1327.0               1      2.0         10.0  \n",
       "2             1327.0               1      3.0         10.0  \n",
       "3             1327.0               1      4.0         10.0  \n",
       "4             1327.0               1      5.0         10.0  \n",
       "...              ...             ...      ...          ...  \n",
       "88911         1327.0               1     10.0          9.0  \n",
       "88912         1327.0               1     11.0          9.0  \n",
       "88913         1327.0               1     12.0          9.0  \n",
       "88914         1327.0               1     13.0          9.0  \n",
       "88915         1327.0               1     14.0          9.0  \n",
       "\n",
       "[88916 rows x 9 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.73\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.91      0.79      7908\n",
      "           1       1.00      1.00      1.00      3219\n",
      "           2       0.91      0.30      0.45       196\n",
      "           3       0.61      0.60      0.60      3968\n",
      "           4       0.83      0.08      0.15      2493\n",
      "\n",
      "    accuracy                           0.73     17784\n",
      "   macro avg       0.81      0.58      0.60     17784\n",
      "weighted avg       0.75      0.73      0.69     17784\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Identify categorical features present in X\n",
    "categorical_features = ['gender', 'is_confirmed_ap', 'in_hospital_death']\n",
    "\n",
    "# Ensure categorical features are of type 'str' or 'category'\n",
    "for col in categorical_features:\n",
    "    if col in X.columns:\n",
    "        X[col] = X[col].astype(str)\n",
    "    else:\n",
    "        raise KeyError(f\"'{col}' column is missing from the features DataFrame.\")\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create Pool for CatBoost\n",
    "train_pool = Pool(X_train, y_train, cat_features=categorical_features)\n",
    "test_pool = Pool(X_test, y_test, cat_features=categorical_features)\n",
    "\n",
    "# Initialize and train the model\n",
    "model = CatBoostClassifier(iterations=100, learning_rate=0.1, depth=6, verbose=0)\n",
    "model.fit(train_pool)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(test_pool)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nan\\anaconda3\\envs\\nansang\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.6317 - loss: 0.8464 - val_accuracy: 0.6717 - val_loss: 0.7464\n",
      "Epoch 2/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.6786 - loss: 0.7384 - val_accuracy: 0.6780 - val_loss: 0.7282\n",
      "Epoch 3/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - accuracy: 0.6809 - loss: 0.7285 - val_accuracy: 0.6812 - val_loss: 0.7241\n",
      "Epoch 4/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.6788 - loss: 0.7207 - val_accuracy: 0.6796 - val_loss: 0.7247\n",
      "Epoch 5/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.6811 - loss: 0.7182 - val_accuracy: 0.6879 - val_loss: 0.7136\n",
      "Epoch 6/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - accuracy: 0.6834 - loss: 0.7131 - val_accuracy: 0.6859 - val_loss: 0.7144\n",
      "Epoch 7/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.6869 - loss: 0.7081 - val_accuracy: 0.6895 - val_loss: 0.7035\n",
      "Epoch 8/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.6894 - loss: 0.7011 - val_accuracy: 0.6876 - val_loss: 0.7018\n",
      "Epoch 9/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.6887 - loss: 0.7026 - val_accuracy: 0.6797 - val_loss: 0.7083\n",
      "Epoch 10/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - accuracy: 0.6906 - loss: 0.6988 - val_accuracy: 0.6900 - val_loss: 0.6977\n",
      "Epoch 11/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - accuracy: 0.6924 - loss: 0.6925 - val_accuracy: 0.6934 - val_loss: 0.6855\n",
      "Epoch 12/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.6944 - loss: 0.6853 - val_accuracy: 0.6880 - val_loss: 0.6871\n",
      "Epoch 13/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.6947 - loss: 0.6836 - val_accuracy: 0.6945 - val_loss: 0.6891\n",
      "Epoch 14/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - accuracy: 0.6960 - loss: 0.6798 - val_accuracy: 0.6972 - val_loss: 0.6796\n",
      "Epoch 15/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.6986 - loss: 0.6779 - val_accuracy: 0.6951 - val_loss: 0.6829\n",
      "Epoch 16/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.6955 - loss: 0.6810 - val_accuracy: 0.6979 - val_loss: 0.6687\n",
      "Epoch 17/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - accuracy: 0.7005 - loss: 0.6757 - val_accuracy: 0.6986 - val_loss: 0.6710\n",
      "Epoch 18/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.6983 - loss: 0.6703 - val_accuracy: 0.6981 - val_loss: 0.6705\n",
      "Epoch 19/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.7002 - loss: 0.6677 - val_accuracy: 0.7027 - val_loss: 0.6638\n",
      "Epoch 20/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.7017 - loss: 0.6686 - val_accuracy: 0.7053 - val_loss: 0.6588\n",
      "Epoch 21/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.7029 - loss: 0.6686 - val_accuracy: 0.7030 - val_loss: 0.6599\n",
      "Epoch 22/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - accuracy: 0.7049 - loss: 0.6598 - val_accuracy: 0.7017 - val_loss: 0.6611\n",
      "Epoch 23/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - accuracy: 0.7041 - loss: 0.6607 - val_accuracy: 0.7001 - val_loss: 0.6532\n",
      "Epoch 24/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - accuracy: 0.7063 - loss: 0.6582 - val_accuracy: 0.7048 - val_loss: 0.6664\n",
      "Epoch 25/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - accuracy: 0.7101 - loss: 0.6514 - val_accuracy: 0.7088 - val_loss: 0.6529\n",
      "Epoch 26/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - accuracy: 0.7058 - loss: 0.6543 - val_accuracy: 0.7038 - val_loss: 0.6533\n",
      "Epoch 27/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - accuracy: 0.7077 - loss: 0.6563 - val_accuracy: 0.7130 - val_loss: 0.6411\n",
      "Epoch 28/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - accuracy: 0.7118 - loss: 0.6468 - val_accuracy: 0.7091 - val_loss: 0.6473\n",
      "Epoch 29/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.7120 - loss: 0.6434 - val_accuracy: 0.7097 - val_loss: 0.6576\n",
      "Epoch 30/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7112 - loss: 0.6490 - val_accuracy: 0.7097 - val_loss: 0.6471\n",
      "Epoch 31/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7083 - loss: 0.6482 - val_accuracy: 0.7117 - val_loss: 0.6472\n",
      "Epoch 32/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.7174 - loss: 0.6441 - val_accuracy: 0.7162 - val_loss: 0.6374\n",
      "Epoch 33/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - accuracy: 0.7143 - loss: 0.6370 - val_accuracy: 0.7158 - val_loss: 0.6364\n",
      "Epoch 34/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - accuracy: 0.7154 - loss: 0.6420 - val_accuracy: 0.7155 - val_loss: 0.6356\n",
      "Epoch 35/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.7164 - loss: 0.6348 - val_accuracy: 0.7139 - val_loss: 0.6335\n",
      "Epoch 36/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - accuracy: 0.7164 - loss: 0.6315 - val_accuracy: 0.7155 - val_loss: 0.6314\n",
      "Epoch 37/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.7160 - loss: 0.6372 - val_accuracy: 0.7145 - val_loss: 0.6428\n",
      "Epoch 38/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - accuracy: 0.7183 - loss: 0.6315 - val_accuracy: 0.6997 - val_loss: 0.6713\n",
      "Epoch 39/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - accuracy: 0.7194 - loss: 0.6358 - val_accuracy: 0.7141 - val_loss: 0.6420\n",
      "Epoch 40/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - accuracy: 0.7198 - loss: 0.6282 - val_accuracy: 0.7158 - val_loss: 0.6364\n",
      "Epoch 41/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - accuracy: 0.7188 - loss: 0.6322 - val_accuracy: 0.7169 - val_loss: 0.6356\n",
      "Epoch 42/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - accuracy: 0.7184 - loss: 0.6311 - val_accuracy: 0.7216 - val_loss: 0.6275\n",
      "Epoch 43/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - accuracy: 0.7221 - loss: 0.6258 - val_accuracy: 0.7167 - val_loss: 0.6267\n",
      "Epoch 44/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - accuracy: 0.7232 - loss: 0.6227 - val_accuracy: 0.7193 - val_loss: 0.6250\n",
      "Epoch 45/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - accuracy: 0.7225 - loss: 0.6250 - val_accuracy: 0.7250 - val_loss: 0.6195\n",
      "Epoch 46/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - accuracy: 0.7266 - loss: 0.6191 - val_accuracy: 0.7219 - val_loss: 0.6283\n",
      "Epoch 47/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - accuracy: 0.7267 - loss: 0.6190 - val_accuracy: 0.7290 - val_loss: 0.6191\n",
      "Epoch 48/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - accuracy: 0.7257 - loss: 0.6228 - val_accuracy: 0.7238 - val_loss: 0.6192\n",
      "Epoch 49/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - accuracy: 0.7301 - loss: 0.6136 - val_accuracy: 0.7212 - val_loss: 0.6237\n",
      "Epoch 50/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - accuracy: 0.7257 - loss: 0.6143 - val_accuracy: 0.7269 - val_loss: 0.6161\n",
      "Epoch 51/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - accuracy: 0.7268 - loss: 0.6169 - val_accuracy: 0.7184 - val_loss: 0.6331\n",
      "Epoch 52/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - accuracy: 0.7253 - loss: 0.6150 - val_accuracy: 0.7247 - val_loss: 0.6230\n",
      "Epoch 53/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - accuracy: 0.7309 - loss: 0.6099 - val_accuracy: 0.7267 - val_loss: 0.6126\n",
      "Epoch 54/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - accuracy: 0.7328 - loss: 0.6069 - val_accuracy: 0.7316 - val_loss: 0.6071\n",
      "Epoch 55/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - accuracy: 0.7309 - loss: 0.6069 - val_accuracy: 0.7314 - val_loss: 0.6119\n",
      "Epoch 56/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - accuracy: 0.7300 - loss: 0.6085 - val_accuracy: 0.7293 - val_loss: 0.6160\n",
      "Epoch 57/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7289 - loss: 0.6066 - val_accuracy: 0.7330 - val_loss: 0.6024\n",
      "Epoch 58/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.7289 - loss: 0.6095 - val_accuracy: 0.7266 - val_loss: 0.6081\n",
      "Epoch 59/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - accuracy: 0.7291 - loss: 0.6044 - val_accuracy: 0.7278 - val_loss: 0.6104\n",
      "Epoch 60/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7308 - loss: 0.6020 - val_accuracy: 0.7311 - val_loss: 0.6106\n",
      "Epoch 61/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7345 - loss: 0.6012 - val_accuracy: 0.7347 - val_loss: 0.6013\n",
      "Epoch 62/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.7323 - loss: 0.6028 - val_accuracy: 0.7326 - val_loss: 0.6118\n",
      "Epoch 63/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.7339 - loss: 0.6106 - val_accuracy: 0.7283 - val_loss: 0.6032\n",
      "Epoch 64/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.7316 - loss: 0.5993 - val_accuracy: 0.7331 - val_loss: 0.6038\n",
      "Epoch 65/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7355 - loss: 0.5959 - val_accuracy: 0.7294 - val_loss: 0.6055\n",
      "Epoch 66/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step - accuracy: 0.7357 - loss: 0.5949 - val_accuracy: 0.7296 - val_loss: 0.6030\n",
      "Epoch 67/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - accuracy: 0.7368 - loss: 0.5945 - val_accuracy: 0.7309 - val_loss: 0.6016\n",
      "Epoch 68/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - accuracy: 0.7362 - loss: 0.5968 - val_accuracy: 0.7394 - val_loss: 0.5922\n",
      "Epoch 69/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.7374 - loss: 0.5991 - val_accuracy: 0.7379 - val_loss: 0.5990\n",
      "Epoch 70/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7370 - loss: 0.5909 - val_accuracy: 0.7311 - val_loss: 0.6067\n",
      "Epoch 71/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.7343 - loss: 0.5963 - val_accuracy: 0.7319 - val_loss: 0.6118\n",
      "Epoch 72/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.7360 - loss: 0.5926 - val_accuracy: 0.7336 - val_loss: 0.6176\n",
      "Epoch 73/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.7388 - loss: 0.5925 - val_accuracy: 0.7408 - val_loss: 0.5908\n",
      "Epoch 74/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.7422 - loss: 0.5840 - val_accuracy: 0.7342 - val_loss: 0.5978\n",
      "Epoch 75/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.7406 - loss: 0.5916 - val_accuracy: 0.7347 - val_loss: 0.6052\n",
      "Epoch 76/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.7391 - loss: 0.5900 - val_accuracy: 0.7323 - val_loss: 0.6045\n",
      "Epoch 77/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.7424 - loss: 0.5867 - val_accuracy: 0.7359 - val_loss: 0.5991\n",
      "Epoch 78/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.7399 - loss: 0.5920 - val_accuracy: 0.7323 - val_loss: 0.5992\n",
      "Epoch 79/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.7412 - loss: 0.5865 - val_accuracy: 0.7368 - val_loss: 0.5965\n",
      "Epoch 80/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - accuracy: 0.7387 - loss: 0.5890 - val_accuracy: 0.7424 - val_loss: 0.5860\n",
      "Epoch 81/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - accuracy: 0.7415 - loss: 0.5847 - val_accuracy: 0.7401 - val_loss: 0.5866\n",
      "Epoch 82/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - accuracy: 0.7423 - loss: 0.5854 - val_accuracy: 0.7364 - val_loss: 0.5970\n",
      "Epoch 83/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.7417 - loss: 0.5814 - val_accuracy: 0.7423 - val_loss: 0.5846\n",
      "Epoch 84/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.7418 - loss: 0.5806 - val_accuracy: 0.7359 - val_loss: 0.5993\n",
      "Epoch 85/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.7424 - loss: 0.5809 - val_accuracy: 0.7411 - val_loss: 0.5993\n",
      "Epoch 86/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.7426 - loss: 0.5790 - val_accuracy: 0.7413 - val_loss: 0.5897\n",
      "Epoch 87/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.7426 - loss: 0.5799 - val_accuracy: 0.7360 - val_loss: 0.5870\n",
      "Epoch 88/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.7450 - loss: 0.5784 - val_accuracy: 0.7394 - val_loss: 0.5871\n",
      "Epoch 89/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.7446 - loss: 0.5894 - val_accuracy: 0.7408 - val_loss: 0.5863\n",
      "Epoch 90/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - accuracy: 0.7446 - loss: 0.5762 - val_accuracy: 0.7406 - val_loss: 0.5865\n",
      "Epoch 91/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.7454 - loss: 0.5817 - val_accuracy: 0.7453 - val_loss: 0.5791\n",
      "Epoch 92/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.7480 - loss: 0.5741 - val_accuracy: 0.7411 - val_loss: 0.5898\n",
      "Epoch 93/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.7469 - loss: 0.5751 - val_accuracy: 0.7387 - val_loss: 0.5914\n",
      "Epoch 94/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - accuracy: 0.7444 - loss: 0.5801 - val_accuracy: 0.7406 - val_loss: 0.5834\n",
      "Epoch 95/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.7462 - loss: 0.5741 - val_accuracy: 0.7512 - val_loss: 0.5687\n",
      "Epoch 96/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - accuracy: 0.7463 - loss: 0.5737 - val_accuracy: 0.7437 - val_loss: 0.5856\n",
      "Epoch 97/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - accuracy: 0.7425 - loss: 0.5784 - val_accuracy: 0.7491 - val_loss: 0.5732\n",
      "Epoch 98/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.7478 - loss: 0.5724 - val_accuracy: 0.7457 - val_loss: 0.5744\n",
      "Epoch 99/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - accuracy: 0.7459 - loss: 0.5706 - val_accuracy: 0.7375 - val_loss: 0.6033\n",
      "Epoch 100/100\n",
      "\u001b[1m5691/5691\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.7458 - loss: 0.5760 - val_accuracy: 0.7434 - val_loss: 0.5782\n",
      "\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 889us/step\n",
      "Accuracy: 0.74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.89      0.79      7908\n",
      "           1       1.00      1.00      1.00      3219\n",
      "           2       0.95      0.18      0.31       196\n",
      "           3       0.62      0.58      0.60      3968\n",
      "           4       0.58      0.25      0.35      2493\n",
      "\n",
      "    accuracy                           0.74     17784\n",
      "   macro avg       0.77      0.58      0.61     17784\n",
      "weighted avg       0.73      0.74      0.72     17784\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Convert target variable to one-hot encoded format\n",
    "y_train_encoded = to_categorical(y_train)\n",
    "y_test_encoded = to_categorical(y_test)\n",
    "\n",
    "# Build a DNN model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))  \n",
    "model.add(Dense(32, activation='relu'))                             \n",
    "model.add(Dense(16, activation='relu'))                              \n",
    "model.add(Dense(8, activation='relu'))                             \n",
    "model.add(Dense(len(np.unique(y_train)), activation='softmax'))      \n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train_encoded, epochs=100, batch_size=10, validation_split=0.2)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Calculate accuracy and display the classification report\n",
    "accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(classification_report(y_test, y_pred_classes))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nansang",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
